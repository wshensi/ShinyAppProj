[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "1 üìò Storyboard\nThis report is part of Take-home Exercise 3 for ISSS608: Visual Analytics and Applications.\nFor group consistency and reference, please refer to Wang Anqi‚Äôs published version.\nAll analyses, code, and visualizations are replicated and extended based on our joint discussion."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For the purpose of this exercise, four R packages will be used. They are tidyverse, jsonlite, tidygraph and ggraph.\nIn the code chunk below,¬†p_load()¬†of¬†pacman¬†package is used to load the R packages into R environemnt.\n\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph)\n\n\n\n\nFor the purpose of this exercise, MC1_graph.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of kg object.\nIn the code chunk below str() is used to reveal the structure of kg object.\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nNext,¬†as_tibble()¬†of¬†tibble¬†package package is used to extract the nodes and links tibble data frames from¬†kg¬†object into two separate tibble data frames called¬†nodes_tbl¬†and¬†edges_tbl¬†respectively.\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links) \n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Edge Type field of edges_tbl.\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hands, code chunk below uses ggplot2 functions to reveal the frequency distribution of¬†Node Type¬†field of¬†nodes_tbl.\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we can go ahead to build the tidygraph object, it is important for us to ensures each id from the node list is mapped to the correct row number. This requirement can be achive by using the code chunk below.\n\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\n\n\n\nNext, we will map the source and the target IDs to row indices by using the code chunk below.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n\nLastly, the code chunk below will be used to exclude the unmatch edges.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\n\nLastly, tbl_graph() is used to create tidygraph‚Äôs graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl, \n                   edges = edges_tbl, \n                   directed = kg$directed)\n\nYou might want to confirm the output object is indeed in tidygraph format by using the code chunk below.\n\nclass(graph)\n\n[1] \"tbl_graph\" \"igraph\"   \n\n\n\n\n\n\nIn this section, we will use ggraph‚Äôs functions to visualise and analyse the graph object.\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)\n\n\n\nIn the code chunk below, ggraph functions are used to visualise the whole graph.\n\n\n# ggraph(graph, layout = \"fr\") +\n#   geom_edge_link(alpha = 0.3, \n#                  colour = \"gray\") +\n#   geom_node_point(aes(color = `Node Type`), \n#                   size = 4) +\n#   geom_node_text(aes(label = name), \n#                  repel = TRUE, \n#                  size = 2.5) +\n#   theme_void()\n\nNotice that the whole graph is very messy and we can hardy discover any useful patterns. This is always the case in graph visualisation and analysis. In order to gain meaningful visual discovery, it is always useful for us to looking into the details, for example by plotting sub-graphs.\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf value in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n\n\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id)  # optional cleanup\n\n\n\n\n\nggraph(graph_memberof, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), \n                  size = 1) +\n  geom_node_text(aes(label = name), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\nNotice that the sub-graph above is very clear and the relationship between musical group and person can be visualise easily.\n\n\n\n\n\n\n\n\nTo understand Sailor Shift‚Äôs musical inspirations and early career influences, we analyzed all incoming edges directed to her node labeled as \"InStyleOf\", \"CoverOf\", and \"DirectlySamples\".\nA stacked bar chart was created to visualize the top 10 artists who most influenced Sailor Shift, categorized by type of influence. This analysis revealed that her style was shaped by a variety of artists, with influences ranging from stylistic imitation to direct sampling and covers.\nThis suggests that Sailor‚Äôs artistic development was not limited to a single mentor or genre, but instead built upon a diverse foundation of musical inspirations.\n\nsailor_id &lt;- nodes_tbl %&gt;% filter(name == \"Sailor Shift\") %&gt;% pull(id)\n\nin_edges &lt;- edges_tbl %&gt;%\n  filter(target == sailor_id,\n         `Edge Type` %in% c(\"InStyleOf\", \"CoverOf\", \"DirectlySamples\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(id, name), by = c(\"source\" = \"id\"))\n\nin_edges %&gt;%\n  filter(name != \"0\") %&gt;%\n  count(name, `Edge Type`, sort = TRUE) %&gt;%\n  group_by(name) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  ungroup() %&gt;%\n  slice_max(order_by = total, n = 10) %&gt;%\n  ggplot(aes(x = reorder(name, total), y = n, fill = `Edge Type`)) +\n  geom_col(width = 0.6) +\n  coord_flip() +\n  labs(title = \"Top 10 Influencers of Sailor Shift\",\n       x = \"Artist\", y = \"Frequency\",\n       fill = \"Type of Influence\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nTo assess Sailor Shift‚Äôs direct impact on the music community, we examined all outgoing edges from her node, focusing again on \"InStyleOf\", \"CoverOf\", and \"DirectlySamples\".\nThe top 10 recipients of her influence were visualized in a stacked bar chart, highlighting the nature and frequency of the influence relationships. This illustrates the artists who either borrowed stylistically from Sailor or engaged with her work directly through covers or sampling.\nThe visualization shows that Sailor played an active and multifaceted role in shaping the musical directions of several notable artists. Her influence extended into both Oceanus Folk and adjacent genres, establishing her as a key figure in the evolving music landscape.\n\nsailor_id &lt;- nodes_tbl %&gt;% filter(name == \"Sailor Shift\") %&gt;% pull(id)\n\nout_edges &lt;- edges_tbl %&gt;%\n  filter(source == sailor_id,\n         `Edge Type` %in% c(\"InStyleOf\", \"CoverOf\", \"DirectlySamples\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(id, name), by = c(\"target\" = \"id\"))\n\nout_edges %&gt;%\n  filter(name != \"0\") %&gt;%\n  count(name, `Edge Type`, sort = TRUE) %&gt;%\n  group_by(name) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  ungroup() %&gt;%\n  slice_max(order_by = total, n = 10) %&gt;%\n  ggplot(aes(x = reorder(name, total), y = n, fill = `Edge Type`)) +\n  geom_col(width = 0.6) +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Artists Influenced by Sailor Shift\",\n    x = \"Artist\", y = \"Influence Frequency\",\n    fill = \"Type of Influence\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo understand Sailor Shift‚Äôs extended influence, we examined not only the artists directly influenced by her, but also those who were influenced indirectly via her collaborators. Specifically, we traced all edges where Sailor was the source (direct influence), and then followed the influence paths of her direct collaborators (second-degree influence).\n\n\n\n\nSailor Shift directly influenced 3 artists through collaborations or stylistic influence.\n\n\n\nThese collaborators subsequently influenced 2 additional artists.\n\n\n\nIn total, her influence extends across 6 unique individuals through two layers.\n\n\n\nAmong the second-degree influenced artists, none were explicitly labeled under the ‚ÄúOceanus Folk‚Äù genre (suggesting that her influence transcended genres).\n\n\n\n\nAlthough none of the second-degree influenced artists were tagged as ‚ÄúOceanus Folk‚Äù, Sailor‚Äôs influence propagated through her collaborators to shape a broader group of artists. This highlights her role as a catalyst within the network, enabling stylistic diffusion even when the final recipients fall outside her original genre.\nThis pattern suggests that Sailor served as a bridge between Oceanus Folk and other genres, allowing her influence to transcend traditional boundaries and seed innovation across the music ecosystem."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For the purpose of this exercise, four R packages will be used. They are tidyverse, jsonlite, tidygraph and ggraph.\nIn the code chunk below,¬†p_load()¬†of¬†pacman¬†package is used to load the R packages into R environemnt.\n\npacman::p_load(tidyverse, jsonlite,\n               tidygraph, ggraph)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-kownledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-kownledge-graph-data",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For the purpose of this exercise, MC1_graph.json file will be used. Before getting started, you should have the data set in the data sub-folder.\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC1_graph.json file into R and save the output object\n\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\nBefore preparing the data, it is always a good practice to examine the structure of kg object.\nIn the code chunk below str() is used to reveal the structure of kg object.\n\nstr(kg, max.level = 1)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Next,¬†as_tibble()¬†of¬†tibble¬†package package is used to extract the nodes and links tibble data frames from¬†kg¬†object into two separate tibble data frames called¬†nodes_tbl¬†and¬†edges_tbl¬†respectively.\n\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tbl &lt;- as_tibble(kg$links) \n\n\n\nIt is time for us to apply appropriate EDA methods to examine the data.\nIn this code chunk below, ggplot2 functions are used the reveal the frequency distribution of Edge Type field of edges_tbl.\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nOn the other hands, code chunk below uses ggplot2 functions to reveal the frequency distribution of¬†Node Type¬†field of¬†nodes_tbl.\n\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "Before we can go ahead to build the tidygraph object, it is important for us to ensures each id from the node list is mapped to the correct row number. This requirement can be achive by using the code chunk below.\n\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\n\n\n\nNext, we will map the source and the target IDs to row indices by using the code chunk below.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n\nLastly, the code chunk below will be used to exclude the unmatch edges.\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\n\nLastly, tbl_graph() is used to create tidygraph‚Äôs graph object by using the code chunk below.\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl, \n                   edges = edges_tbl, \n                   directed = kg$directed)\n\nYou might want to confirm the output object is indeed in tidygraph format by using the code chunk below.\n\nclass(graph)\n\n[1] \"tbl_graph\" \"igraph\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-knowledge-graph",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-knowledge-graph",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "In this section, we will use ggraph‚Äôs functions to visualise and analyse the graph object.\nSeveral of the ggraph layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\nset.seed(1234)\n\n\n\nIn the code chunk below, ggraph functions are used to visualise the whole graph.\n\n\n# ggraph(graph, layout = \"fr\") +\n#   geom_edge_link(alpha = 0.3, \n#                  colour = \"gray\") +\n#   geom_node_point(aes(color = `Node Type`), \n#                   size = 4) +\n#   geom_node_text(aes(label = name), \n#                  repel = TRUE, \n#                  size = 2.5) +\n#   theme_void()\n\nNotice that the whole graph is very messy and we can hardy discover any useful patterns. This is always the case in graph visualisation and analysis. In order to gain meaningful visual discovery, it is always useful for us to looking into the details, for example by plotting sub-graphs.\n\n\n\nIn this section, we are interested to create a sub-graph base on MemberOf value in Edge Type column of the edges data frame.\n\n\n\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n\n\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\n\n\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id)  # optional cleanup\n\n\n\n\n\nggraph(graph_memberof, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`), \n                  size = 1) +\n  geom_node_text(aes(label = name), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\n\n\n\n\nNotice that the sub-graph above is very clear and the relationship between musical group and person can be visualise easily."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a.-who-influenced-sailor-shift",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#a.-who-influenced-sailor-shift",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "To understand Sailor Shift‚Äôs musical inspirations and early career influences, we analyzed all incoming edges directed to her node labeled as \"InStyleOf\", \"CoverOf\", and \"DirectlySamples\".\nA stacked bar chart was created to visualize the top 10 artists who most influenced Sailor Shift, categorized by type of influence. This analysis revealed that her style was shaped by a variety of artists, with influences ranging from stylistic imitation to direct sampling and covers.\nThis suggests that Sailor‚Äôs artistic development was not limited to a single mentor or genre, but instead built upon a diverse foundation of musical inspirations.\n\nsailor_id &lt;- nodes_tbl %&gt;% filter(name == \"Sailor Shift\") %&gt;% pull(id)\n\nin_edges &lt;- edges_tbl %&gt;%\n  filter(target == sailor_id,\n         `Edge Type` %in% c(\"InStyleOf\", \"CoverOf\", \"DirectlySamples\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(id, name), by = c(\"source\" = \"id\"))\n\nin_edges %&gt;%\n  filter(name != \"0\") %&gt;%\n  count(name, `Edge Type`, sort = TRUE) %&gt;%\n  group_by(name) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  ungroup() %&gt;%\n  slice_max(order_by = total, n = 10) %&gt;%\n  ggplot(aes(x = reorder(name, total), y = n, fill = `Edge Type`)) +\n  geom_col(width = 0.6) +\n  coord_flip() +\n  labs(title = \"Top 10 Influencers of Sailor Shift\",\n       x = \"Artist\", y = \"Frequency\",\n       fill = \"Type of Influence\") +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b.-who-did-sailor-shift-influence",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#b.-who-did-sailor-shift-influence",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "To assess Sailor Shift‚Äôs direct impact on the music community, we examined all outgoing edges from her node, focusing again on \"InStyleOf\", \"CoverOf\", and \"DirectlySamples\".\nThe top 10 recipients of her influence were visualized in a stacked bar chart, highlighting the nature and frequency of the influence relationships. This illustrates the artists who either borrowed stylistically from Sailor or engaged with her work directly through covers or sampling.\nThe visualization shows that Sailor played an active and multifaceted role in shaping the musical directions of several notable artists. Her influence extended into both Oceanus Folk and adjacent genres, establishing her as a key figure in the evolving music landscape.\n\nsailor_id &lt;- nodes_tbl %&gt;% filter(name == \"Sailor Shift\") %&gt;% pull(id)\n\nout_edges &lt;- edges_tbl %&gt;%\n  filter(source == sailor_id,\n         `Edge Type` %in% c(\"InStyleOf\", \"CoverOf\", \"DirectlySamples\")) %&gt;%\n  left_join(nodes_tbl %&gt;% select(id, name), by = c(\"target\" = \"id\"))\n\nout_edges %&gt;%\n  filter(name != \"0\") %&gt;%\n  count(name, `Edge Type`, sort = TRUE) %&gt;%\n  group_by(name) %&gt;%\n  mutate(total = sum(n)) %&gt;%\n  ungroup() %&gt;%\n  slice_max(order_by = total, n = 10) %&gt;%\n  ggplot(aes(x = reorder(name, total), y = n, fill = `Edge Type`)) +\n  geom_col(width = 0.6) +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Artists Influenced by Sailor Shift\",\n    x = \"Artist\", y = \"Influence Frequency\",\n    fill = \"Type of Influence\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c.-how-did-sailor-shift-influence-collaborators-of-the-broader-oceanus-folk-community",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#c.-how-did-sailor-shift-influence-collaborators-of-the-broader-oceanus-folk-community",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "To understand Sailor Shift‚Äôs extended influence, we examined not only the artists directly influenced by her, but also those who were influenced indirectly via her collaborators. Specifically, we traced all edges where Sailor was the source (direct influence), and then followed the influence paths of her direct collaborators (second-degree influence).\n\n\n\n\nSailor Shift directly influenced 3 artists through collaborations or stylistic influence.\n\n\n\nThese collaborators subsequently influenced 2 additional artists.\n\n\n\nIn total, her influence extends across 6 unique individuals through two layers.\n\n\n\nAmong the second-degree influenced artists, none were explicitly labeled under the ‚ÄúOceanus Folk‚Äù genre (suggesting that her influence transcended genres).\n\n\n\n\nAlthough none of the second-degree influenced artists were tagged as ‚ÄúOceanus Folk‚Äù, Sailor‚Äôs influence propagated through her collaborators to shape a broader group of artists. This highlights her role as a catalyst within the network, enabling stylistic diffusion even when the final recipients fall outside her original genre.\nThis pattern suggests that Sailor served as a bridge between Oceanus Folk and other genres, allowing her influence to transcend traditional boundaries and seed innovation across the music ecosystem."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "",
    "text": "This page presents a visualisation critique and redesign based on a submission by my course-mate, XU XINYI, for the third exploratory data analysis task (EDA 3). The original plot titled ‚ÄúBox Plot with Data Superimposed ‚Äì Population by Age Group (30‚Äì49), Across Planning Areas (2024)‚Äù used faceted box plots to visualize population distribution across six major planning areas in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#load-packages",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nThe following R packages will be loaded using the¬†pacman::p_load()¬†function.\n\npacman::p_load(tidyverse, haven,\n               ggrepel, ggthemes,\n               ggridges, ggdist,\n               patchwork, scales, ggExtra)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#import-data",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.2 Import data",
    "text": "2.2 Import data\nTo accomplish the task, Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024 dataset shares by¬†Department of Statistics, Singapore (DOS)¬†should be used.\nThe code chunk below imports respopagesex2024.csv into R environment by using read_csv()function of readr package. readr is one of the tidyverse package.\nWe import this dataset as sgresident\n\nsgresident &lt;- read_csv(\"data/respopagesex2024.csv \")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#data-preprocessing",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#data-preprocessing",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.3 Data preprocessing",
    "text": "2.3 Data preprocessing\nWe first take a look at the data and check if there are any duplicates.\n\nglimpse(sgresident)\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K‚Ä¶\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T‚Ä¶\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", ‚Ä¶\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male‚Ä¶\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3‚Ä¶\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,‚Ä¶\n\n\n\nsgresident[duplicated(sgresident),]\n\n# A tibble: 0 √ó 6\n# ‚Ñπ 6 variables: PA &lt;chr&gt;, SZ &lt;chr&gt;, Age &lt;chr&gt;, Sex &lt;chr&gt;, Pop &lt;dbl&gt;,\n#   Time &lt;dbl&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#change-data-type-of-selected-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#change-data-type-of-selected-variables",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.4 Change data type of selected variables",
    "text": "2.4 Change data type of selected variables\nVariables with inappropriate data type are Age, Sex, Time.¬†\n\nsgresident &lt;- sgresident %&gt;% \n  mutate(Age = as.numeric(Age))\nsgresident &lt;- sgresident %&gt;%\n  mutate(Sex = factor(Sex, levels = c(\"Males\", \"Females\")))\nsgresident &lt;- sgresident %&gt;%\n  mutate(Time = as.integer(Time))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#check-for-missing-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#check-for-missing-values",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.5 Check for missing values",
    "text": "2.5 Check for missing values\nThe age column has 664 missing values, which have been stored as strings before data type conversion. In this case, we do not need to remove those data.\n\ncolSums(is.na(sgresident ))\n\n  PA   SZ  Age  Sex  Pop Time \n   0    0  664    0    0    0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#preview-pre-processed-dataframe",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#preview-pre-processed-dataframe",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "2.6 Preview pre-processed dataframe",
    "text": "2.6 Preview pre-processed dataframe\nWe use the function¬†head()¬†to preview the first few rows of the pre-processed dataframe:\n\nhead(sgresident, 200)\n\n# A tibble: 200 √ó 6\n   PA         SZ                       Age Sex       Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre     0 Males      10  2024\n 2 Ang Mo Kio Ang Mo Kio Town Centre     0 Females    10  2024\n 3 Ang Mo Kio Ang Mo Kio Town Centre     1 Males      10  2024\n 4 Ang Mo Kio Ang Mo Kio Town Centre     1 Females    10  2024\n 5 Ang Mo Kio Ang Mo Kio Town Centre     2 Males      10  2024\n 6 Ang Mo Kio Ang Mo Kio Town Centre     2 Females    10  2024\n 7 Ang Mo Kio Ang Mo Kio Town Centre     3 Males      10  2024\n 8 Ang Mo Kio Ang Mo Kio Town Centre     3 Females    10  2024\n 9 Ang Mo Kio Ang Mo Kio Town Centre     4 Males      30  2024\n10 Ang Mo Kio Ang Mo Kio Town Centre     4 Females    10  2024\n# ‚Ñπ 190 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#original-work",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#original-work",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "3.1 Original Work",
    "text": "3.1 Original Work\nThe visualisation I selected for critique is the third exploratory data analysis (EDA) plot submitted by my classmate, titled ‚ÄúEDA 3: Box Plot with Data Superimposed ‚Äì Population by Age Group (30‚Äì49), Across Planning Areas (2024).‚Äù\nThis is a faceted boxplot with raw data values superimposed, designed to visualise the population distribution of individuals aged 30 to 49 across six major planning areas in Singapore for the year 2024.\nEach planning area is displayed in a separate facet, allowing for structured comparisons across regions. The visual reveals that Tampines and Bedok have relatively high and consistent population levels across all age bands within the 30‚Äì49 range, whereas Sengkang and Punggol show pronounced peaks between ages 35 and 44, reflecting their family-oriented demographic profiles. The use of a logarithmic y-axis serves to highlight disparities between densely and sparsely populated subzones, improving the perceptibility of variation across different scales.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 1: Prepare data\ndf_pa_box &lt;- sgresident %&gt;%\n  mutate(\n    Age = as.numeric(Age),\n    AgeGroup = cut(\n      Age,\n      breaks = seq(0, 100, by = 5),\n      right = FALSE,\n      include.lowest = TRUE,\n      labels = paste(seq(0, 95, by = 5), seq(4, 99, by = 5), sep = \"-\")\n    )\n  ) %&gt;%\n  filter(Age &gt;= 30, Age &lt; 50) %&gt;%\n  drop_na(AgeGroup)\n\n# Optional: focus only on top 6 PAs for readability\ntop6_pa &lt;- df_pa_box %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop)) %&gt;%\n  arrange(desc(Total_Pop)) %&gt;%\n  slice_head(n = 6) %&gt;%\n  pull(PA)\n\ndf_pa_box &lt;- df_pa_box %&gt;% filter(PA %in% top6_pa)\n\n# Step 2: Boxplot with jittered data, faceted by PA\nggplot(df_pa_box, aes(x = AgeGroup, y = Pop)) +\n  geom_boxplot(fill = \"steelblue\", alpha = 0.6, outlier.shape = NA) +\n  geom_jitter(width = 0.2, alpha = 0.4, color = \"black\", size = 0.8) +\n  scale_y_log10() +\n  facet_wrap(~ PA, scales = \"free_y\") +\n  labs(\n    title = \"Population Distribution by Age Group (30‚Äì49), Faceted by Planning Area\",\n    x = \"Age Group\", y = \"Population (log scale)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#good-visual-design-principles",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#good-visual-design-principles",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "4.1 Good Visual Design Principles",
    "text": "4.1 Good Visual Design Principles\n\n4.1.1 Faceted Layout Enables Clear Regional Comparison\nThe original chart adopts a faceted layout based on Planning Areas, which allows readers to easily compare intra-region age distributions as well as inter-region demographic trends. This structure enhances analytical clarity by organizing data into manageable visual units.\n\n\n4.1.2 Superimposed Raw Data Points Enhance Distribution Transparency\nBy overlaying raw population data on each boxplot, the visualisation goes beyond summary statistics and allows viewers to see the spread, density, and presence of outliers in each age group. This contributes to a more data-transparent and trustworthy representation.\n\n\n4.1.3 Logarithmic Scale Effectively Handles Skewed Data\nThe use of a log-transformed y-axis appropriately addresses large disparities in population counts across planning areas. It compresses extreme values and prevents dominant regions from visually overshadowing those with smaller populations, thereby supporting a fairer visual comparison."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#further-improvement",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.2.html#further-improvement",
    "title": "Take-home Exercise 1 (Part 2)",
    "section": "4.2 Further Improvement",
    "text": "4.2 Further Improvement\n\n4.2.1 Age Range Selection is Narrow, Limiting Holistic Insights\nThe original visualization only focuses on the 30‚Äì49 age group, which captures a working-age population but neglects other important demographic segments such as youths and the elderly. By restricting the age scope, the chart omits critical signals related to ageing populations and young family concentrations. The revised version addresses this by including the full age spectrum, providing a more comprehensive demographic perspective.\n\n\n4.2.2 Visual Complexity Reduces Interpretability\nWith six separate panels, numerous overlaid data points, and a log-scaled axis, the original chart demands high cognitive effort. Viewers may find it difficult to extract key insights at a glance. In contrast, the revised visual adopts a consolidated layout, plotting all planning areas on the same axis, which facilitates faster and more effective interpretation.\n\n\n4.2.3 Lack of Statistical Annotations and Visual Emphasis\nWhile the original boxplots display medians and quartiles, they omit key statistical markers such as weighted mean age or explicit group-level annotations. The revised version improves upon this by adding red diamonds to indicate weighted means and black dots for medians. These additions guide attention to population central tendencies and enhance overall communicative clarity."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "MC1: The Rising",
    "section": "",
    "text": "pacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph)\nkg &lt;- fromJSON(\"data/MC1_graph.json\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#initial-eda",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#initial-eda",
    "title": "MC1: The Rising",
    "section": "1 Initial EDA",
    "text": "1 Initial EDA\n\nggplot(data = edges_tbl,\n       aes(y = `Edge Type`)) +\n  geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#creating-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#creating-knowledge-graph",
    "title": "MC1: The Rising",
    "section": "2 Creating Knowledge Graph",
    "text": "2 Creating Knowledge Graph\nThis is\n\n2.1 Step 1: Mapping from node id to row index\n\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)))\n\nThis ensures each id from your node list is mapped to the correct row number.\n\n\n2.2 Step 2: Map source and target IDs to row indices\n\nedges_tbl &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n2.3 Step 3: Filter our any unmatched (invalid) edges\n\nedges_tbl &lt;- edges_tbl %&gt;% \n  filter(!is.na(from), !is.na(to))\n\n\n\n2.4 Step 4: Creating the graph\nLastly, tbl_graph() is used to create tidygraph‚Äôs graph object by is uing the code chunk below:\n\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tbl,\n                   directed = kg$directed)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-the-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-the-knowledge-graph",
    "title": "MC1: The Rising",
    "section": "3 Visualizing the knowledge graph",
    "text": "3 Visualizing the knowledge graph\n\nset.seed(1234)\n\n\n3.1 Visualizing the whole Graph\n\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,\n                 color = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 4) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()\n\n\n\n3.2 Visualizing the sub-graph\nIn this section, we are interested to create a sub-graph based on ‚ÄúMemberof‚Äù value in\n\n3.2.1 Step 1: Filter edges to only ‚ÄúMemberOf‚Äù\n\ngraph_memberof &lt;- graph %&gt;% \n  activate(edges) %&gt;% \n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n3.2.2 Step 2: Extract only connected nodes (i.e., used in these edges)\n\nused_node_indices &lt;- graph_memberof %&gt;% \n  activate(edges) %&gt;% \n  as_tibble() %&gt;% \n  select(from, to) %&gt;% \n  unlist() %&gt;% \n  unique()\n\n\n\n3.2.3 Step 3: Keep only those nodes\n\ngraph_memberof &lt;- graph_memberof %&gt;% \n  activate(nodes) %&gt;% \n  mutate(row_id = row_number()) %&gt;% \n  filter(row_id %in% used_node_indices) %&gt;% \n  select(-row_id)\n\n\n\n3.2.4 Plot the sub-graph\n\nggraph(graph_memberof,\n      layout = \"fr\") +\n  geom_edge_link(alpha = 0.5,\n                 color = \"gray\") + \n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#superstore-sales-and-profit-report",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#superstore-sales-and-profit-report",
    "title": "In-class Exercise 1",
    "section": "2 Superstore Sales and Profit Report",
    "text": "2 Superstore Sales and Profit Report\nHere is the sales and profit report visualized using Tableau:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It‚Äôs display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly‚Äôs JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, the¬†Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018¬†data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called¬†respopagsex2000to2018_tidy.csv¬†and is in csv file format.\n\n\n\nTo important¬†respopagsex2000to2018_tidy.csv¬†into R,¬†read_csv()¬†function of¬†readr¬†package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the¬†mutate()¬†function of¬†dplyr¬†package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\nUse¬†ggtern()¬†function of¬†ggtern¬†package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using¬†plot_ly()¬†function of¬†Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It‚Äôs display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly‚Äôs JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the¬†Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018¬†data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called¬†respopagsex2000to2018_tidy.csv¬†and is in csv file format.\n\n\n\nTo important¬†respopagsex2000to2018_tidy.csv¬†into R,¬†read_csv()¬†function of¬†readr¬†package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the¬†mutate()¬†function of¬†dplyr¬†package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "",
    "text": "Use¬†ggtern()¬†function of¬†ggtern¬†package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using¬†plot_ly()¬†function of¬†Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-1",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression‚Äôs estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that ‚Äúsimilar‚Äù variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.2 Installing and Launching R Packages",
    "text": "2.2 Installing and Launching R Packages\nBefore you get started, you are required to open a new Quarto document. Keep the default html authoring format.\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.3 Importing and Preparing The Data Set",
    "text": "2.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the¬†Wine Quality Data Set¬†of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n2.3.1 Importing Data\nFirst, let us import the data into R by using¬†read_csv()¬†of¬†readr¬†package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.4 Building Correlation Matrix: pairs() method",
    "text": "2.4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n2.4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of¬†pairs()¬†can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default¬†pairs¬†function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n2.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n2.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon‚Äôt worry about the details for now-just type this code into your R session or script. Let‚Äôs have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.5 Visualising Correlation Matrix: ggcormat()",
    "text": "2.5 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e.¬†more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n2.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it‚Äôs ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-multiple-plots",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.6 Building multiple plots",
    "text": "2.6 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in¬†ggcorrmat()¬†but in the¬†grouped_ggcorrmat()¬†of¬†ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "2.7 Visualising Correlation Matrix using corrplot Package",
    "text": "2.7 Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n2.7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext,¬†corrplot()¬†is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as¬†saturation¬†is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n2.7.2 Working with visual geometrics\nIn¬†corrplot¬†package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the¬†method¬†argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\nFeel free to change the¬†method¬†argument to other supported visual geometrics.\n\n\n2.7.3 Working with layout\ncorrplor()¬†supports three layout types, namely: ‚Äúfull‚Äù, ‚Äúupper‚Äù or ‚Äúlower‚Äù. The default is ‚Äúfull‚Äù which display full matrix. The default setting can be changed by using the¬†type¬†argument of¬†corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments¬†diag¬†and¬†tl.col¬†are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as¬†tl.pos,¬†tl.cex,¬†tl.offset,¬†cl.pos,¬†cl.cex¬†and¬†cl.offset, just to mention a few of them.\n\n\n2.7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument¬†lower¬†and¬†upper¬†are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e.¬†number) is used to map the upper half of the corrgram. The argument¬†tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the¬†diag¬†argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n2.7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the¬†cor.mtest()¬†to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the¬†p.mat¬†argument of¬†corrplot¬†function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n2.7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e.¬†‚Äúoriginal‚Äù). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n‚ÄúAOE‚Äù is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n‚ÄúFPC‚Äù for the first principal component order.\n‚Äúhclust‚Äù for hierarchical clustering order, and ‚Äúhclust.method‚Äù for the agglomeration method to be used.\n\n‚Äúhclust.method‚Äù should be one of ‚Äúward‚Äù, ‚Äúsingle‚Äù, ‚Äúcomplete‚Äù, ‚Äúaverage‚Äù, ‚Äúmcquitty‚Äù, ‚Äúmedian‚Äù or ‚Äúcentroid‚Äù.\n\n‚Äúalphabet‚Äù for alphabetical order.\n\n‚ÄúAOE‚Äù, ‚ÄúFPC‚Äù, ‚Äúhclust‚Äù, ‚Äúalphabet‚Äù. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n2.7.7 Reordering a correlation matrix using hclust\nIf using¬†hclust,¬†corrplot()¬†can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#r-packages",
    "title": "Hands-on Exercise 9 (Part 1 & 2)",
    "section": "3.1 R packages",
    "text": "3.1 R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, I learnt how to plot functional and truthful choropleth maps by using an R package called¬†tmap¬†package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#introduction",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#introduction",
    "title": "Hands-on Exercise 8",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, I learnt how to plot functional and truthful choropleth maps by using an R package called¬†tmap¬†package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\n2.1 Installing and launching R packages\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "title": "Hands-on Exercise 8",
    "section": "3 Importing Data into R",
    "text": "3 Importing Data into R\n\n3.1 Importing Geospatial Data into R\nThe code chunk below uses the¬†st_read()¬†function of¬†sf¬†package to import¬†MP14_SUBZONE_WEB_PL¬†shapefile into R as a simple feature data frame called¬†mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\wshensi\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nShow data table:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n3.2 Importing Attribute Data into R\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n3.3 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.3.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n3.3.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext,¬†left_join()¬†of¬†dplyr¬†is used to join the geographical data and attribute table using planning subzone name e.g.¬†SUBZONE_N¬†and¬†SZ¬†as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8",
    "section": "4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "4 Choropleth Mapping Geospatial Data Using tmap\n\n4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with ‚Äúplot‚Äù option is used to produce a static map. For interactive mode, ‚Äúview‚Äù option should be used.\nfill argument is used to map the attribute (i.e.¬†DEPENDENCY)\n\n\n\n4.2 Creating a choropleth map by using tmap‚Äôs elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of¬†qtm()¬†is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below,¬†tmap‚Äôs drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is ‚Äúsolid‚Äù.\n\n\n\n\n4.3 Data classification methods of tmap\n\n4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below,¬†equal¬†data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.2 Plotting choropleth map with custome break\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of¬†DEPENDENCY¬†field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n4.4 Colour Scheme\n\n4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to¬†values¬†argument of¬†tm_scale_intervals()¬†as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a ‚Äú-‚Äù prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n4.5 Map Layouts\n\n4.5.1 Map Legend\nIn¬†tmap, several¬†tm_legend()¬†options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n4.6 Drawing Small Multiple Choropleth Maps\n\n4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining¬†ncols¬†in¬†tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using¬†tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with¬†tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eference",
    "title": "Hands-on Exercise 8",
    "section": "5 eference",
    "text": "5 eference\n\n5.1 21.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n5.2 21.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n5.3 21.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‚Äòspread()‚Äô and ‚Äògather()‚Äô Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html",
    "title": "Hands-on Exercise 8.2",
    "section": "",
    "text": "Before we get started, we need to ensure that¬†tmap¬†package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\npackage 'logger' successfully unpacked and MD5 sums checked\npackage 'geometries' successfully unpacked and MD5 sums checked\npackage 'rapidjsonr' successfully unpacked and MD5 sums checked\npackage 'sfheaders' successfully unpacked and MD5 sums checked\npackage 'png' successfully unpacked and MD5 sums checked\npackage 'stringdist' successfully unpacked and MD5 sums checked\npackage 'spacesXYZ' successfully unpacked and MD5 sums checked\npackage 'geojsonsf' successfully unpacked and MD5 sums checked\npackage 'raster' successfully unpacked and MD5 sums checked\npackage 'jsonify' successfully unpacked and MD5 sums checked\npackage 'leaflet.providers' successfully unpacked and MD5 sums checked\npackage 'sp' successfully unpacked and MD5 sums checked\npackage 'terra' successfully unpacked and MD5 sums checked\npackage 'slippymath' successfully unpacked and MD5 sums checked\npackage 'lwgeom' successfully unpacked and MD5 sums checked\npackage 'dichromat' successfully unpacked and MD5 sums checked\npackage 'XML' successfully unpacked and MD5 sums checked\npackage 'cols4all' successfully unpacked and MD5 sums checked\npackage 'leafem' successfully unpacked and MD5 sums checked\npackage 'leafgl' successfully unpacked and MD5 sums checked\npackage 'leaflegend' successfully unpacked and MD5 sums checked\npackage 'leaflet' successfully unpacked and MD5 sums checked\npackage 'leafsync' successfully unpacked and MD5 sums checked\npackage 'maptiles' successfully unpacked and MD5 sums checked\npackage 'stars' successfully unpacked and MD5 sums checked\npackage 'tmaptools' successfully unpacked and MD5 sums checked\npackage 'servr' successfully unpacked and MD5 sums checked\npackage 'tmap' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Shensi\\AppData\\Local\\Temp\\RtmpWUVCOX\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-import-and-preparation",
    "title": "Hands-on Exercise 8.2",
    "section": "2.1 Data Import and Preparation",
    "text": "2.1 Data Import and Preparation\nThe code chunk below uses¬†read_csv()¬†function of¬†readr¬†package to import¬†SGPools_svy21.csv¬†into R as a tibble data frame called¬†sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nShow data table:\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 √ó 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar‚Ä¶ 2 Bayf‚Ä¶    18972 30842. 29599. Branch                        5\n 2 Livewire (Res‚Ä¶ 26 Sen‚Ä¶    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K‚Ä¶ Lotus ‚Ä¶   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P‚Ä¶ 1 Sele‚Ä¶   188306 29777. 31382. Branch                       44\n 5 Prime Serango‚Ä¶ Blk 54‚Ä¶   552542 32239. 39519. Branch                        0\n 6 Singapore Poo‚Ä¶ 1A Woo‚Ä¶   731001 21012. 46987. Branch                        3\n 7 Singapore Poo‚Ä¶ Blk 64‚Ä¶   370064 33990. 34356. Branch                       17\n 8 Singapore Poo‚Ä¶ Blk 88‚Ä¶   370088 33847. 33976. Branch                       16\n 9 Singapore Poo‚Ä¶ Blk 30‚Ä¶   540308 33910. 41275. Branch                       21\n10 Singapore Poo‚Ä¶ Blk 20‚Ä¶   560202 29246. 38943. Branch                       25\n# ‚Ñπ 296 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 8.2",
    "section": "2.2 Creating a sf data frame from an aspatial data frame",
    "text": "2.2 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using¬†st_as_sf()¬†of¬†sf¬†packages\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 √ó 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf‚Ä¶    18972 Branch                        5\n 2 Livewire (Resorts World Sen‚Ä¶ 26 Sen‚Ä¶    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus ‚Ä¶   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele‚Ä¶   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54‚Ä¶   552542 Branch                        0\n 6 Singapore Pools Woodlands C‚Ä¶ 1A Woo‚Ä¶   731001 Branch                        3\n 7 Singapore Pools 64 Circuit ‚Ä¶ Blk 64‚Ä¶   370064 Branch                       17\n 8 Singapore Pools 88 Circuit ‚Ä¶ Blk 88‚Ä¶   370088 Branch                       16\n 9 Singapore Pools Anchorvale ‚Ä¶ Blk 30‚Ä¶   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio ‚Ä¶ Blk 20‚Ä¶   560202 Branch                       25\n# ‚Ñπ 296 more rows\n# ‚Ñπ 1 more variable: geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#it-all-started-with-an-interactive-point-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#it-all-started-with-an-interactive-point-symbol-map",
    "title": "Hands-on Exercise 8.2",
    "section": "3.1 It all started with an interactive point symbol map",
    "text": "3.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-make-it-proportional",
    "title": "Hands-on Exercise 8.2",
    "section": "3.2 Lets make it proportional",
    "text": "3.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable¬†Gp1Gp2Winnings¬†is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#lets-give-it-a-different-colour",
    "title": "Hands-on Exercise 8.2",
    "section": "3.3 Lets give it a different colour",
    "text": "3.3 Lets give it a different colour\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#i-have-a-twin-brothers",
    "title": "Hands-on Exercise 8.2",
    "section": "3.4 I have a twin brothers :)",
    "text": "3.4 I have a twin brothers :)\n\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch¬†tmap‚Äôs Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#all-about-tmap-package",
    "title": "Hands-on Exercise 8.2",
    "section": "4.1 27.1 All about tmap package",
    "text": "4.1 27.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 8.2",
    "section": "4.2 27.2 Geospatial data wrangling",
    "text": "4.2 27.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.2.html#data-wrangling",
    "title": "Hands-on Exercise 8.2",
    "section": "4.3 27.3 Data wrangling",
    "text": "4.3 27.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‚Äòspread()‚Äô and ‚Äògather()‚Äô Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and¬†lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Hands-on Exercise 5",
    "section": "3 The Data",
    "text": "3 The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n3.1 The edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n3.2 The nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n3.3 Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using¬†read_csv()¬†of¬†readr¬†package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using¬†glimpse()¬†of¬†dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26‚Ä¶\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29‚Ä¶\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"‚Ä¶\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0‚Ä¶\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP‚Ä¶\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela‚Ä¶\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr‚Ä¶\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc‚Ä¶\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the¬†SentDate¬†is treated as ‚ÄúCharacter‚Äù data type instead of¬†date¬†data type. This is an error! Before we continue, it is important for us to change the data type of¬†SentDate¬†field back to ‚ÄúDate‚Äù‚Äù data type.\n\n\n\n\n3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e.¬†Monday. The function will create a new column in the data.frame i.e.¬†Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted¬†GAStech_edges¬†data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26‚Ä¶\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29‚Ä¶\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"‚Ä¶\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0‚Ä¶\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP‚Ä¶\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela‚Ä¶\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr‚Ä¶\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc‚Ä¶\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0‚Ä¶\n$ Weekday     &lt;ord&gt; ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î‚Ä¶\n\n\n\n\n3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n(), .groups = \"drop\") %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n3.8 Reviewing the revised edges file\nTable below shows the data structure of the reformatted¬†GAStech_edges¬†data frame\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26‚Ä¶\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29‚Ä¶\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"‚Ä¶\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0‚Ä¶\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP‚Ä¶\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela‚Ä¶\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr‚Ä¶\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc‚Ä¶\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0‚Ä¶\n$ Weekday     &lt;ord&gt; ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î, ÊòüÊúü‰∫î‚Ä¶"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 5",
    "section": "4 Creating network objects using tidygraph",
    "text": "4 Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n4.1 The tbl_graph object\nTwo functions of¬†tidygraph¬†package can be used to create network objects, they are\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\n\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph‚Äôs network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n4.4 Reviewing the output tidygraph‚Äôs graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 √ó 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana‚Ä¶\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ‚Ñπ 44 more rows\n#\n# Edge Data: 1,372 √ó 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 ÊòüÊúüÊó•       5\n2     1     2 ÊòüÊúü‰∏Ä       2\n3     1     2 ÊòüÊúü‰∫å       3\n# ‚Ñπ 1,369 more rows\n\n\n\n\n4.5 Reviewing the output tidygraph‚Äôs graph object\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of ‚ÄúNode Data‚Äù and the first three of ‚ÄúEdge Data‚Äù.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest ‚Äúweight‚Äù first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 √ó 4 (active)\n    from    to Weekday Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n 1    40    41 ÊòüÊúüÂÖ≠      13\n 2    41    43 ÊòüÊúü‰∏Ä      11\n 3    35    31 ÊòüÊúü‰∫å      10\n 4    40    41 ÊòüÊúü‰∏Ä      10\n 5    40    43 ÊòüÊúü‰∏Ä      10\n 6    36    32 ÊòüÊúüÊó•       9\n 7    40    43 ÊòüÊúüÂÖ≠       9\n 8    41    40 ÊòüÊúü‰∏Ä       9\n 9    19    15 ÊòüÊúü‰∏â       8\n10    35    38 ÊòüÊúü‰∫å       8\n# ‚Ñπ 1,362 more rows\n#\n# Node Data: 54 √ó 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ‚Ñπ 51 more rows\n\n\nVisit the reference guide of¬†activate()¬†to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 5",
    "section": "5 Plotting Static Network Graphs with ggraph package",
    "text": "5 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph‚Äôs network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n5.1 Plotting a basic network graph\nThe code chunk below uses¬†ggraph(),¬†geom-edge_link()¬†and¬†geom_node_point()¬†to plot a network graph by using¬†GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n5.2 Changing the default network graph theme\nIn this section, you will use¬†theme_graph()¬†to remove the x and y axes. Before your get started, it is advisable to read it‚Äôs reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n5.3 Changing the coloring of the plot\nFurthermore,¬†theme_graph()¬†makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n5.4 Working with ggraph‚Äôs layouts\nggraph¬†support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by¬†ggraph().\n\n\n\n\n5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the¬†Weight¬†variable.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on Exercise 5",
    "section": "6 Creating facet graphs",
    "text": "6 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n6.1 Working with facet_edges()\nIn the code chunk below,¬†facet_edges()¬†is used. Before getting started, it is advisable for you to read it‚Äôs reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n6.2 Working with facet_edges()\nThe code chunk below uses¬†theme()¬†to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n6.3 framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n6.4 Working with facet_nodes()\nIn the code chunkc below,¬†facet_nodes()¬†is used. Before getting started, it is advisable for you to read it‚Äôs reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on Exercise 5",
    "section": "7 Network Metrics Analysis",
    "text": "7 Network Metrics Analysis\n\n7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to¬†Chapter 7: Actor Prominence¬†of¬†A User‚Äôs Guide to Network Analysis in R¬†to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n7.2 Visualising network metrics\nIt is important to note that from¬†ggraph v2.0¬†onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using¬†geom_mark_hull()¬†of¬†ggforce¬†package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that you must to install and include¬†ggforce¬†and¬†concaveman¬†packages before running the code chunk below.\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 5",
    "section": "8 Building Interactive Network Graph with visNetwork",
    "text": "8 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an ‚Äúid‚Äù column, and the edge list must have ‚Äúfrom‚Äù and ‚Äúto‚Äù columns.\nThe function also plots the labels for the nodes, using the names of the actors from the ‚Äúlabel‚Äù column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit¬†Igraph¬†to find out more about¬†visIgraphLayout‚Äôs argument\n\n\n8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called ‚Äúgroup‚Äù in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the¬†group¬†field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n8.5 Working with visual attributes - Edges\nIn the code run below¬†visEdges()¬†is used to symbolise the edges.\n- The argument¬†arrows¬†is used to define where to place the arrow.\n- The¬†smooth¬†argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit¬†Option¬†to find out more about visEdges‚Äôs argument.\n\n\n8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit¬†Option¬†to find out more about visOption‚Äôs argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reference",
    "title": "Hands-on Exercise 5",
    "section": "9 Reference",
    "text": "9 Reference"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html",
    "title": "Hands-on Exercise 4.3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#learning-outcome",
    "title": "Hands-on Exercise 4.3",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#getting-started",
    "title": "Hands-on Exercise 4.3",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(plotly, crosstalk, DT, \n               ggdist, ggridges, colorspace,\n               gganimate, tidyverse)\n\n\n\n2.2 Data import\nFor the purpose of this exercise,¬†Exam_data.csv¬†will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4.3",
    "section": "3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon‚Äôt confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display¬†my_sum¬†tibble data frame in an html table format.\n\nThe TableThe Code Chunk\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=‚Äúidentity‚Äù.\n\n\n\n\n\n3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the code chunk above\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualizing-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualizing-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4.3",
    "section": "4 Visualizing Uncertainty: ggdist package",
    "text": "4 Visualizing Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(‚Äúfreq-uncertainty-vis‚Äù));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below,¬†stat_pointinterval()¬†of¬†ggdist¬†is used to build a visual for displaying distribution of maths scores by race.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\n95%99%\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.95,\n    show.legend = FALSE\n  ) +\n  labs(\n    title = \"95% Confidence Interval of Mean Math Score\",\n    subtitle = \"Mean Point + 95% Interval\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    .width = 0.99,\n    show.legend = FALSE\n  ) +\n  labs(\n    title = \"99% Confidence Interval of Mean Math Score\",\n    subtitle = \"Mean Point + 99% Interval\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below,¬†stat_gradientinterval()¬†of¬†ggdist¬†is used to build a visual for displaying distribution of maths scores by race.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4.3",
    "section": "5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n5.1 Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\n\n\n5.2 Launch the application in R\n\nlibrary(ungeviz)\n\n\n\n5.3 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\nNext, the code chunk below will be used to build the HOPs.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html",
    "title": "Hands-on Exercise 4.1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#learning-outcome",
    "title": "Hands-on Exercise 4.1",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#getting-started",
    "title": "Hands-on Exercise 4.1",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into RStudio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n2.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#visualizing-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#visualizing-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4.1",
    "section": "3 Visualizing Distribution with Ridgeline Plot",
    "text": "3 Visualizing Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n3.1 Plotting ridgeline graph: ggridges method\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using .geom_density_ridges()\n\nThe plotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n3.2 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either¬†geom_ridgeline_gradient()¬†or¬†geom_density_ridges_gradient(). Both geoms work just like¬†and¬†, except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.geom_ridgeline()geom_density_ridges()\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n3.3 Mapping the probabilities directly onto color\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using which represent the empirical cumulative density function for the distribution of English score.stat(ecdf)\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument¬†in¬†.calc_ecdf = TRUEstat_density_ridges()\n\n\n\n\n3.4 Ridgeline plots with quantile lines\nBy using¬†geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated¬†aesthetic as shown in the figure below.stat(quantile)\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#visualizing-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.1.html#visualizing-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 4.1",
    "section": "4 Visualizing Distribution with Raincloud Plot",
    "text": "4 Visualizing Distribution with Raincloud Plot\nRaincloud Plot is a data visualization techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a ‚Äúraincloud‚Äù. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using¬†geom_boxplot()¬†of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using¬†stat_dots()¬†of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = ‚Äúleft‚Äù to indicate we want it on the left-hand side.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n4.4 Finishing touch\nLastly,¬†coord_flip()¬†of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time,¬†of ggthemes package is used to give the raincloud chart a professional publishing standard look.theme_economist()\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nReference\n\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al.¬†‚ÄúRaincloud plots: a multi-platform tool for robust data. visualization‚Äù [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp.¬†4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html",
    "title": "Hands-on Exercise 3.2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using¬†gganimate¬†and¬†plotly r¬†packages. At the same time, you will also learn how to (i) reshape data by using¬†tidyr¬†package, and (ii) process, wrangle and transform data by using¬†dplyr¬†package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it‚Äôs important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#overview",
    "title": "Hands-on Exercise 3.2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using¬†gganimate¬†and¬†plotly r¬†packages. At the same time, you will also learn how to (i) reshape data by using¬†tidyr¬†package, and (ii) process, wrangle and transform data by using¬†dplyr¬†package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it‚Äôs important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#getting-started",
    "title": "Hands-on Exercise 3.2",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Loading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant‚Äôs fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\n\n\n\n\n\nLoad the Packages\n\n\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\n\n2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately,¬†mutate_each_()¬†was deprecated in dplyr 0.7.0. and¬†funs()¬†was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using¬†mutate_at()¬†as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using¬†mutate_at(),¬†across()¬†can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3.2",
    "section": "3 Animated Data Visualisation: gganimate methods",
    "text": "3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nStatic Bubble PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e.¬†Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nAnimated Bubble PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3.2",
    "section": "4 Animated Data Visualisation: plotly",
    "text": "4 Animated Data Visualisation: plotly\nIn¬†Plotly R¬†package, both¬†ggplotly()¬†and¬†plot_ly()¬†support key frame animations through the¬†frame¬†argument/aesthetic. They also support an¬†ids¬†argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using¬†ggplotly()¬†method.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although¬†show.legend = FALSE¬†argument was used, the legend still appears on the plot. To overcome this problem,¬†theme(legend.position='none')¬†should be used as shown in the plot and code chunk below.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using¬†plot_ly()¬†method.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.2.html#reference",
    "title": "Hands-on Exercise 3.2",
    "section": "5 Reference",
    "text": "5 Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "title": "Hands-on Exercise 1",
    "section": "2.1 Geometric Objects: geom_bar",
    "text": "2.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using¬†geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "title": "Hands-on Exercise 1",
    "section": "2.2 Geometric Objects: geom_dotplot",
    "text": "2.2 Geometric Objects: geom_dotplot\nIn the code chunk below,¬†geom_dotplot()¬†of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "title": "Hands-on Exercise 1",
    "section": "2.3 Geometric Objects: geom_histogram()",
    "text": "2.3 Geometric Objects: geom_histogram()\nIn the code chunk below,¬†geom_histogram()¬†is used to create a simple histogram by using values in¬†MATHS¬†field of¬†exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands-on Exercise 1",
    "section": "2.4 Modifying a geometric object by changing geom()",
    "text": "2.4 Modifying a geometric object by changing geom()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands-on Exercise 1",
    "section": "2.5 Modifying a geometric object by changing aes()",
    "text": "2.5 Modifying a geometric object by changing aes()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "title": "Hands-on Exercise 1",
    "section": "2.6 Geometric Objects: geom-density()",
    "text": "2.6 Geometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using¬†colour¬†or¬†fill¬†arguments of¬†aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hands-on Exercise 1",
    "section": "2.7 Geometric Objects: geom_boxplot",
    "text": "2.7 Geometric Objects: geom_boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "title": "Hands-on Exercise 1",
    "section": "2.8 Geometric Objects: geom_violin",
    "text": "2.8 Geometric Objects: geom_violin\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hands-on Exercise 1",
    "section": "2.9 Geometric Objects: geom_point()",
    "text": "2.9 Geometric Objects: geom_point()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "title": "Hands-on Exercise 1",
    "section": "2.10 Geom Objects can be combined",
    "text": "2.10 Geom Objects can be combined\nThe code chunk below plots the data points on the boxplots by using both¬†geom_boxplot()¬†and¬†geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "2.11 Essential Grammatical Elements in ggplot2: stat",
    "text": "2.11 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "title": "Hands-on Exercise 1",
    "section": "2.12 Working with stat()",
    "text": "2.12 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1",
    "section": "2.13 Working with stat - the stat_summary() method",
    "text": "2.13 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using¬†stat_summary()¬†function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1",
    "section": "2.14 Working with stat - the geom() method",
    "text": "2.14 Working with stat - the geom() method\nThe code chunk below adding mean values by using¬†geom_()¬†function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands-on Exercise 1",
    "section": "2.15 Adding a best fit curve on a scatterplot?",
    "text": "2.15 Adding a best fit curve on a scatterplot?\nIn the code chunk below,¬†geom_smooth()¬†is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "2.16 Essential Grammatical Elements in ggplot2: Facets",
    "text": "2.16 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely:¬†facet_grid()¬†and¬†facet_wrap.\n\n2.16.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n2.16.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "2.17 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "2.17 Essential Grammatical Elements in ggplot2: Coordinates\nThe¬†Coordinates¬†functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped.\n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot).\n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n2.17.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using¬†coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n2.17.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "2.18 Essential Grammatical Elements in ggplot2: themes",
    "text": "2.18 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g.¬†x-axis), a rectangle (e.g.¬†graph background), or text (e.g.¬†axis title).\n\n2.18.1 Working with theme\nThe code chunk below plot a horizontal bar chart using¬†theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using¬†theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using¬†theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "2.19 Reference",
    "text": "2.19 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper ‚Äì Components\nLearning ggplot2 on Paper ‚Äì Layer\nLearning ggplot2 on Paper ‚Äì Scale"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ISSS608-VAA- About",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. Code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse) \n\n\n\n\nThe code chunk below imports¬†exam_data.csv¬†into R environment by using¬†read_csv()¬†function of¬†readr¬†package.¬†readr¬†is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data02.csv\", show_col_types = FALSE)\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\nggplot2 comes with eight¬†built-in themes, they are:¬†,¬†,¬†,¬†,¬†,¬†,¬†, and¬†.theme_gray()theme_bw()theme_classic()theme_dark()theme_light()theme_linedraw()theme_minimal()theme_void()\nThe Plot:\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\nRefer to this¬†link¬†to learn more about ggplot2¬†Themes\n\n\nggthemes¬†provides¬†‚Äòggplot2‚Äô themes¬†that replicate the look of plots by Edward Tufte, Stephen Few,¬†Fivethirtyeight,¬†The Economist, ‚ÄòStata‚Äô, ‚ÄòExcel‚Äô, and¬†The Wall Street Journal, among others.\nIn the example below,¬†The Economist¬†theme is used.\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\nIt also provides some extra geoms and scales for ‚Äòggplot2‚Äô. Consult¬†this vignette¬†to learn more.\n\n\n\nhrbrthemes¬†package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\nThe second goal centers around productivity for a production workflow. In fact, this ‚Äúproduction workflow‚Äù is the context for where the elements of hrbrthemes should be used. Consult¬†this vignette¬†to learn more.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\nNext\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np1 + p2\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n‚Äú/‚Äù operator to stack two ggplot2 graphs,\n‚Äú|‚Äù operator to place the plots beside each other,\n‚Äú()‚Äù operator the define the sequence of the plotting.\n\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\n(p1 / p2) | p3\n\nTo learn more about, refer to¬†Plot Assembly.\n\n\n\nIn order to identify subplots in text,¬†patchwork¬†also provides auto-tagging capabilities as shown in the figure below.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With¬†inset_element()¬†of¬†patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. Code chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse) \n\n\n\n\nThe code chunk below imports¬†exam_data.csv¬†into R environment by using¬†read_csv()¬†function of¬†readr¬†package.¬†readr¬†is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data02.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "ggplot2 comes with eight¬†built-in themes, they are:¬†,¬†,¬†,¬†,¬†,¬†,¬†, and¬†.theme_gray()theme_bw()theme_classic()theme_dark()theme_light()theme_linedraw()theme_minimal()theme_void()\nThe Plot:\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\nRefer to this¬†link¬†to learn more about ggplot2¬†Themes\n\n\nggthemes¬†provides¬†‚Äòggplot2‚Äô themes¬†that replicate the look of plots by Edward Tufte, Stephen Few,¬†Fivethirtyeight,¬†The Economist, ‚ÄòStata‚Äô, ‚ÄòExcel‚Äô, and¬†The Wall Street Journal, among others.\nIn the example below,¬†The Economist¬†theme is used.\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\nIt also provides some extra geoms and scales for ‚Äòggplot2‚Äô. Consult¬†this vignette¬†to learn more.\n\n\n\nhrbrthemes¬†package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\nThe second goal centers around productivity for a production workflow. In fact, this ‚Äúproduction workflow‚Äù is the context for where the elements of hrbrthemes should be used. Consult¬†this vignette¬†to learn more.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "It is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunk below.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\nNext\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np1 + p2\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n‚Äú/‚Äù operator to stack two ggplot2 graphs,\n‚Äú|‚Äù operator to place the plots beside each other,\n‚Äú()‚Äù operator the define the sequence of the plotting.\n\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\n(p1 / p2) | p3\n\nTo learn more about, refer to¬†Plot Assembly.\n\n\n\nIn order to identify subplots in text,¬†patchwork¬†also provides auto-tagging capabilities as shown in the figure below.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With¬†inset_element()¬†of¬†patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\nThe Plot:\n\n\n\n\n\n\n\n\n\nThe Code:\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "Patchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3.1",
    "section": "",
    "text": "In this hands-on exercise, we learn how to create interactive data visualisation by using functions provided by¬†ggiraph¬†and¬†plotlyr¬†packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "title": "Hands-on Exercise 3.1",
    "section": "",
    "text": "In this hands-on exercise, we learn how to create interactive data visualisation by using functions provided by¬†ggiraph¬†and¬†plotlyr¬†packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3.1",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nFirst, write a code to check, install and launch the following R packages:\n\nggiraph for making ‚Äòggplot‚Äô graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3.1",
    "section": "3 Importing Data",
    "text": "3 Importing Data\nIn this section, the Exam_data.csv file will be used. The read_csv() function from the readr package is employed to import the dataset into R.\nThe code chunk below demonstrates how read_csv() is used to read the Exam_data.csv file and store it as a tibble data frame named exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "4 Interactive Data Visualisation - ggiraph methods",
    "text": "4 Interactive Data Visualisation - ggiraph methods\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code to plot an interactive statistical graph by using¬†ggiraph¬†package. Notice that the code consists of two parts. First, an ggplot object will be created. Next,¬†girafe()¬†of¬†ggiraph¬†will be used to create an interactive svg object.\n\nOriginalInteractive Tooltip\n\n\nFirst, create the basic graph. We are using interactive version of ggplot2 geom (i.e.¬†geom_dotplot_interactive())\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\ngeom_dotplot_interactive(\n  aes(tooltip = ID),\n  stackgroups = TRUE, \n  binwidth = 1, \n  method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\n\n\n\n\n\n\n\nNext, enable the tooltip using girafe(). This generates an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student‚Äôs ID will be displayed.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(ggobj = p)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "title": "Hands-on Exercise 3.1",
    "section": "5 Displaying multiple information on tooltip",
    "text": "5 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called¬†tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nEnglishMath"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#customizing-tooltip-style",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#customizing-tooltip-style",
    "title": "Hands-on Exercise 3.1",
    "section": "6 Customizing Tooltip style",
    "text": "6 Customizing Tooltip style\nCode below uses¬†opts_tooltip()¬†of¬†ggiraph¬†to customize tooltip rendering by add¬†css¬†declarations.\n\nWhiteThe Code Chunk\n\n\nBackground colour of the tooltip is white and the font colour is black and bold\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,        \n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)   \n\n\n\n\n\n6.1 Displaying statistics on tooltip\nCode below shows an advanced way to customise tooltip. In this example,¬†tooltip¬†and¬†stat_summary¬†are used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-on Exercise 3.1",
    "section": "7 Hover effect with data_id aesthetic",
    "text": "7 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely¬†.data_id\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\nhover_css = ‚Äúfill:orange;‚Äùopts_hover(css = ‚Äúfill: #202020;‚Äù)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a¬†data_id¬†(i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n7.2 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of .onclick\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n7.3 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nThe¬†data_id¬†aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "8 Interactive Data Visualisation - plotly methods!",
    "text": "8 Interactive Data Visualisation - plotly methods!\nPlotly‚Äôs R graphing library create interactive web graphics from¬†ggplot2¬†graphs and/or a custom interface to the (MIT-licensed) JavaScript library¬†plotly.js¬†inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n8.1 Creating an interactive scatter plot: plot_ly() method\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n8.2 Working with visual variable: plot_ly() method\nIn the code chunk below,¬†color¬†argument is mapped to a qualitative visual variable (i.e.¬†RACE).\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n8.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using¬†ggplotly().\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n8.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3.1",
    "section": "9 Interactive Data Visualisation - crosstalk methods!",
    "text": "9 Interactive Data Visualisation - crosstalk methods!\nCrosstalk¬†is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n9.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‚ÄòDataTables‚Äô (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n9.2 Linked brushing: crosstalk method\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 3.1",
    "section": "10 Reference",
    "text": "10 Reference\n\n10.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n10.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly‚Äôs R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html",
    "title": "Hands-on Exercise 4.2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#learning-outcome",
    "title": "Hands-on Exercise 4.2",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4.2",
    "section": "2 Visual Statistical Analysis with ggstatsplot",
    "text": "2 Visual Statistical Analysis with ggstatsplot\nggstatsplot¬†¬†is an extension of¬†ggplot2¬†package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.2.html#getting-started",
    "title": "Hands-on Exercise 4.2",
    "section": "3 Getting Started",
    "text": "3 Getting Started\n\n3.1 Installing and launching R packages\nIn this exercise,¬†ggstatsplot¬†and¬†tidyverse¬†will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n3.2 Importing data\n\n\n\n\n\n\nDo-It-Myself\n\n\n\nImporting¬†Exam.csv¬†data by using appropriate tidyverse package.\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n3.3 One-sample test: gghistostats() method\nIn the code chunk below,¬†gghistostats()¬†is used to to build an visual of one-sample test on English scores.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n3.4 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat‚Äôs because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n3.5 How to interpret Bayes Factor\nA¬†Bayes Factor¬†can be any positive number. One of the most common interpretations is this one‚Äîfirst proposed by Harold Jeffereys (1961) and slightly modified by¬†Lee and Wagenmakers¬†in 2013:\n\n\n\n3.6 Two-sample mean test: ggbetweenstats()\nIn the code chunk below,¬†ggbetweenstats()¬†is used to build a visual for two-sample mean test of Maths scores by gender.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n3.7 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below,¬†ggbetweenstats()¬†is used to build a visual for One-way ANOVA test on English score by race.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n‚Äúns‚Äù ‚Üí only non-significant\n‚Äús‚Äù ‚Üí only significant\n‚Äúall‚Äù ‚Üí everything\n\n\n3.7.1 ggbetweenstats - Summary of tests\n\n\n\n\n\n\n3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below,¬†ggscatterstats()¬†is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n3.9 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using¬†cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below¬†ggbarstats()¬†is used to build a visual for Significant Test of Association\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html",
    "title": "Hands-on Exercise 4.4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#overview",
    "title": "Hands-on Exercise 4.4",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4.4",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\npackage 'FunnelPlotR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Shensi\\AppData\\Local\\Temp\\RtmpmU4T6d\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#importing-data",
    "title": "Hands-on Exercise 4.4",
    "section": "3 Importing Data",
    "text": "3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e.¬†kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4.4",
    "section": "4 FunnelPlotR methods",
    "text": "4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n4.1 FunnelPlotR methods: The basic plot\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e.¬†Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is ‚ÄúSR‚Äù.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion.\nThings to learn from the code chunk above. +¬†data_type¬†argument is used to change from default ‚ÄúSR‚Äù to ‚ÄúPR‚Äù (i.e.¬†proportions). +¬†xrange¬†and¬†yrange¬†are used to set the range of x-axis and y-axis\n\n\n4.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion.\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4.4",
    "section": "5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the¬†fit.mean¬†is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with¬†ggplotly()¬†of¬†plotly¬†r package.\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.4.html#references",
    "title": "Hands-on Exercise 4.4",
    "section": "6 References",
    "text": "6 References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise,¬†eventlog.csv¬†file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n¬†kable()¬†can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\nmake_hr_weekday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, tz = \"UTC\", quiet = TRUE) %&gt;%\n    with_tz(tzone = tz[1])\n  \n  dt &lt;- data.table(\n    source_country = sc,\n    wkday = lubridate::wday(real_times, label = TRUE, abbr = FALSE, week_start = 1),\n    hour = hour(real_times)\n  )\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_weekday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(wkday, levels = wkday_levels),  # To keep the order\n         hour = factor(hour, levels = 0:23)\n)\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n22\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nTW\nSunday\n10\n\n\nAfrica/Cairo\nCN\nSunday\n13\n\n\nAfrica/Cairo\nUS\nSunday\n17\n\n\nAfrica/Cairo\nCA\nMonday\n13\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into¬†attacks¬†data frame,¬†mutate()¬†of¬†dplyr¬†package is used to convert¬†wkday¬†and¬†hour¬†fields into¬†factor¬†so they‚Äôll be ordered when plotting\n\n\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there‚Äôs no need to further preprocess the data.\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nattacks_by_country &lt;- attacks %&gt;%\n  count(source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(source_country, levels = top4)) %&gt;%\n  na.omit()\n\nggplot(data = top4_attacks,\n       aes(x = hour,\n           y = wkday,\n           fill = n)) + \n  geom_tile(color = \"white\",\n            size = 0.1) +\n  facet_wrap(~source_country, ncol = 2) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e.¬†top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise,¬†eventlog.csv¬†file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n¬†kable()¬†can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nSys.setlocale(\"LC_TIME\", \"C\")\n\n[1] \"C\"\n\nmake_hr_weekday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, tz = \"UTC\", quiet = TRUE) %&gt;%\n    with_tz(tzone = tz[1])\n  \n  dt &lt;- data.table(\n    source_country = sc,\n    wkday = lubridate::wday(real_times, label = TRUE, abbr = FALSE, week_start = 1),\n    hour = hour(real_times)\n  )\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_weekday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(wkday, levels = wkday_levels),  # To keep the order\n         hour = factor(hour, levels = 0:23)\n)\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n22\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nTW\nSunday\n10\n\n\nAfrica/Cairo\nCN\nSunday\n13\n\n\nAfrica/Cairo\nUS\nSunday\n17\n\n\nAfrica/Cairo\nCA\nMonday\n13\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into¬†attacks¬†data frame,¬†mutate()¬†of¬†dplyr¬†package is used to convert¬†wkday¬†and¬†hour¬†fields into¬†factor¬†so they‚Äôll be ordered when plotting\n\n\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there‚Äôs no need to further preprocess the data.\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nattacks_by_country &lt;- attacks %&gt;%\n  count(source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(source_country, levels = top4)) %&gt;%\n  na.omit()\n\nggplot(data = top4_attacks,\n       aes(x = hour,\n           y = wkday,\n           fill = n)) + \n  geom_tile(color = \"white\",\n            size = 0.1) +\n  facet_wrap(~source_country, ncol = 2) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e.¬†top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "2 Plotting Cycle Plot",
    "text": "2 Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n2.1 Step 1: Data Import\nThe code chunk below imports¬†arrivals_by_air.xlsx¬†by using¬†read_excel()¬†of¬†readxl¬†package and save it as a tibble data frame called¬†air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n2.2 Step 2: Deriving month and year fields\nNext, two new fields called¬†month¬†and¬†year¬†are derived from¬†Month-Year¬†field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n2.3 Step 4: Extracting the target country\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n2.4 Step 5: Computing year average arrivals by month\nThe code chunk below uses¬†group_by()¬†and¬†summarise()¬†of¬†dplyr¬†to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n2.5 Step 6: Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "3 Plotting Slopegraph",
    "text": "3 Plotting Slopegraph\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n3.1 Step 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n3.2 Step 2: Plotting the slopegraph\n\nThe PlotThe Code Chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design,¬†factor()¬†is used convert the value type of¬†Year¬†field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html",
    "title": "Hands-on Exercise 8.3",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#getting-started",
    "title": "Hands-on Exercise 8.3",
    "section": "",
    "text": "pacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8.3",
    "section": "2 Basic Choropleth Mapping",
    "text": "2 Basic Choropleth Mapping\n\n2.1 Visualising distribution of non-functional water point\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\n\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(fill = \"total_wp\", \n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1, \n             fill_alpha = 1) + \n  tm_title(\"Distribution of total  water point by LGAs\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8.3",
    "section": "3 Choropleth Map for Rates",
    "text": "3 Choropleth Map for Rates\n\n3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n3.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.3.html#extreme-value-maps",
    "title": "Hands-on Exercise 8.3",
    "section": "4 Extreme Value Maps",
    "text": "4 Extreme Value Maps\n\n4.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n4.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n4.1.2 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e.¬†wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.1.3 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n4.1.4 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\n\n4.2 Box map\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n4.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n4.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n4.2.3 Test drive the newly created function\nLet‚Äôs test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n4.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nBefore you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using¬†heatmaply¬†package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables‚Äô values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable‚Äôs distribution while making them easily comparable on the same ‚Äúscale‚Äù.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e.¬†wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e.¬†wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options ‚Äúpearson‚Äù, ‚Äúspearman‚Äù and ‚Äúkendall‚Äù can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in ‚Äúeuclidean‚Äù to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is ‚Äúdist‚Äù‚Äù hence this can be one of ‚Äúeuclidean‚Äù, ‚Äúmaximum‚Äù, ‚Äúmanhattan‚Äù, ‚Äúcanberra‚Äù, ‚Äúbinary‚Äù or ‚Äúminkowski‚Äù.\nhclust_method default is NULL, which results in ‚Äúcomplete‚Äù method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of ‚Äúward.D‚Äù, ‚Äúward.D2‚Äù, ‚Äúsingle‚Äù, ‚Äúcomplete‚Äù, ‚Äúaverage‚Äù (= UPGMA), ‚Äúmcquitty‚Äù (= WPGMA), ‚Äúmedian‚Äù (= WPGMC) or ‚Äúcentroid‚Äù (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with ‚ÄúEuclidean distance‚Äù and ‚Äúward.D‚Äù method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that ‚Äúaverage‚Äù method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn‚Äôt actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can‚Äôt end up between A and B, but it doesn‚Äôt tell you which way to flip the A+B cluster. It doesn‚Äôt tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is ‚ÄúOLO‚Äù (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is ‚ÄúGW‚Äù (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option ‚Äúmean‚Äù gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option ‚Äúnone‚Äù gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "Before you get started, you are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "In this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#static-heatmap",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using¬†heatmaply¬†package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables‚Äô values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable‚Äôs distribution while making them easily comparable on the same ‚Äúscale‚Äù.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e.¬†wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e.¬†wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options ‚Äúpearson‚Äù, ‚Äúspearman‚Äù and ‚Äúkendall‚Äù can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in ‚Äúeuclidean‚Äù to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is ‚Äúdist‚Äù‚Äù hence this can be one of ‚Äúeuclidean‚Äù, ‚Äúmaximum‚Äù, ‚Äúmanhattan‚Äù, ‚Äúcanberra‚Äù, ‚Äúbinary‚Äù or ‚Äúminkowski‚Äù.\nhclust_method default is NULL, which results in ‚Äúcomplete‚Äù method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of ‚Äúward.D‚Äù, ‚Äúward.D2‚Äù, ‚Äúsingle‚Äù, ‚Äúcomplete‚Äù, ‚Äúaverage‚Äù (= UPGMA), ‚Äúmcquitty‚Äù (= WPGMA), ‚Äúmedian‚Äù (= WPGMC) or ‚Äúcentroid‚Äù (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with ‚ÄúEuclidean distance‚Äù and ‚Äúward.D‚Äù method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that ‚Äúaverage‚Äù method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn‚Äôt actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can‚Äôt end up between A and B, but it doesn‚Äôt tell you which way to flip the A+B cluster. It doesn‚Äôt tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is ‚ÄúOLO‚Äù (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is ‚ÄúGW‚Äù (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option ‚Äúmean‚Äù gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option ‚Äúnone‚Äù gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview-1",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nParallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), ‚ÄúThis certainly isn‚Äôt a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn‚Äôt in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.‚Äù For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.2 Installing and Launching R Packages",
    "text": "2.2 Installing and Launching R Packages\nFor this exercise, the GGally, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#data-preparation",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.3 Data Preparation",
    "text": "2.3 Data Preparation\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.4 Plotting Static Parallel Coordinates Plot",
    "text": "2.4 Plotting Static Parallel Coordinates Plot\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n2.4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e.¬†wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n2.4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e.¬†parallel lines) by using a single variable (i.e.¬†Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n2.4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n2.4.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n2.4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme‚Äôs text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "2.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‚Äòhtmlwidgets‚Äô package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n2.5.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n2.5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n2.5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n2.5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#references",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "2.6 References",
    "text": "2.6 References\n\nggparcoord() of GGally package\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#overview-2",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nIn this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#installing-and-launching-r-packages-2",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "3.2 Installing and Launching R Packages",
    "text": "3.2 Installing and Launching R Packages\nBefore we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#data-wrangling",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "3.3 Data Wrangling",
    "text": "3.3 Data Wrangling\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n3.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n3.3.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No.¬†of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they‚Äôll be automatically applied ‚Äúby group‚Äù.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(‚Äúwindow-functions‚Äù).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n3.3.3 Grouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n3.3.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the¬†pipe, %&gt;%:\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "3.4 Designing Treemap with treemap Package",
    "text": "3.4 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n3.4.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n3.4.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it‚Äôs vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n3.4.3 Working with vColor and type arguments\nIn the code chunk below,¬†type¬†argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e.¬†0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n3.4.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between ‚Äúvalue‚Äù and ‚Äúmanual‚Äù is the default value for mapping. The ‚Äúvalue‚Äù treemap considers palette to be a diverging color palette (say ColorBrewer‚Äôs ‚ÄúRdYlBu‚Äù), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The ‚Äúmanual‚Äù treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n3.4.5 The ‚Äúvalue‚Äù type treemap\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n3.4.6 The ‚Äúmanual‚Äù type treemap\nThe ‚Äúmanual‚Äù type does not interpret the values as the ‚Äúvalue‚Äù type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n3.4.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: ‚Äúsquarified‚Äù and ‚ÄúpivotSize‚Äù. The default is ‚ÄúpivotSize‚Äù.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n3.4.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n3.4.9 Using sortID\nWhen ‚ÄúpivotSize‚Äù algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.2.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 9 (Part 3, 4 & 5)",
    "section": "3.5 Designing Treemap using treemapify Package",
    "text": "3.5 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to ‚Äútreemapify‚Äù its user guide.\n\n3.5.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n3.5.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#overview",
    "title": "Hands-on Exercise 10",
    "section": "",
    "text": "By the end of this hands-on exercise, you will be able to:\n\ncreate bullet chart by using ggplot2,\ncreate sparklines by using ggplot2 ,\nbuild industry standard dashboard by using R Shiny."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#getting-started",
    "title": "Hands-on Exercise 10",
    "section": "2 Getting started",
    "text": "2 Getting started\nFor the purpose of this hands-on exercise, the following R packages will be used.\n\n\nShow the code\npacman::p_load(lubridate, ggthemes, reactable,\nreactablefmtr, gt, gtExtras, tidyverse)\n\n\n\ntidyverse provides a collection of functions for performing data science task such as importing, tidying, wrangling data and visualising data. It is not a single package but a collection of modern R packages including but not limited to readr, tidyr, dplyr, ggplot, tibble, stringr, forcats and purrr.\nlubridate provides functions to work with dates and times more efficiently.\nggthemes is an extension of ggplot2. It provides additional themes beyond the basic themes of ggplot2.\ngtExtras provides some additional helper functions to assist in creating beautiful tables with gt, an R package specially designed for anyone to make wonderful-looking tables using the R programming language.\nreactable provides functions to create interactive data tables for R, based on the React Table library and made with reactR.\nreactablefmtr provides various features to streamline and enhance the styling of interactive reactable tables with easy-to-use and highly-customizable functions and themes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-microsoft-access-database",
    "title": "Hands-on Exercise 10",
    "section": "3 Importing Microsoft Access database",
    "text": "3 Importing Microsoft Access database\n\n3.1 The data set\nFor the purpose of this study, a personal database in Microsoft Access mdb format called¬†Coffee Chain¬†will be used.\n\n\n3.2 Importing database into R\nIn the code chunk below,¬†odbcConnectAccess()¬†of¬†RODBC¬†package is used used to import a database query table into R.\n\n\nShow the code\nlibrary(RODBC)\ncon &lt;- odbcConnectAccess2007('data/Coffee Chain.mdb')\ncoffeechain &lt;- sqlFetch(con, 'CoffeeChain Query')\nwrite_rds(coffeechain, \"data/CoffeeChain.rds\")\nodbcClose(con)\n\n\nNote: Before running the code chunk, you need to change the R system to 32bit version. This is because the¬†odbcConnectAccess()¬†is based on 32bit and not 64bit\n\n\n3.3 Data Preparation\nThe code chunk below is used to import¬†CoffeeChain.rds¬†into R.\n\n\nShow the code\ncoffeechain &lt;- read_rds(\"data/CoffeeChain.rds\")\n\n\nNote: This step is optional if coffeechain is already available in R.\nThe code chunk below is used to aggregate Sales and Budgeted Sales at the Product level.\n\n\nShow the code\nproduct &lt;- coffeechain %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`target` = sum(`Budget Sales`),\n            `current` = sum(`Sales`)) %&gt;%\n  ungroup()\n\n\n\n\n3.4 Bullet chart in ggplot2\nThe code chunk below is used to plot the bullet charts using ggplot2 functions.\n\n\nShow the code\nggplot(product, aes(Product, current)) + \n  geom_col(aes(Product, max(target) * 1.01),\n           fill=\"grey85\", width=0.85) +\n  geom_col(aes(Product, target * 0.75),\n           fill=\"grey60\", width=0.85) +\n  geom_col(aes(Product, target * 0.5),\n           fill=\"grey50\", width=0.85) +\n  geom_col(aes(Product, current), \n           width=0.35,\n           fill = \"black\") + \n  geom_errorbar(aes(y = target,\n                    x = Product, \n                    ymin = target,\n                    ymax= target), \n                width = .4,\n                colour = \"red\",\n                size = 1) +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#plotting-sparklines-using-ggplot2",
    "title": "Hands-on Exercise 10",
    "section": "4 Plotting sparklines using ggplot2",
    "text": "4 Plotting sparklines using ggplot2\nIn this section, you will learn how to plot sparklines by using ggplot2.\n\n4.1 Preparing the data\n\n\nShow the code\nsales_report &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  mutate(Month = month(Date)) %&gt;%\n  group_by(Month, Product) %&gt;%\n  summarise(Sales = sum(Sales), .groups = \"drop\") %&gt;%\n  select(Month, Product, Sales)\n\n\nThe code chunk below is used to compute the minimum, maximum and end othe the month sales.\n\n\nShow the code\nmins &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.min(Sales))\nmaxs &lt;- group_by(sales_report, Product) %&gt;% \n  slice(which.max(Sales))\nends &lt;- group_by(sales_report, Product) %&gt;% \n  filter(Month == max(Month))\n\n\nThe code chunk below is used to compute the 25 and 75 quantiles.\n\n\nShow the code\nquarts &lt;- sales_report %&gt;%\n  group_by(Product) %&gt;%\n  summarise(quart1 = quantile(Sales, \n                              0.25),\n            quart2 = quantile(Sales, \n                              0.75)) %&gt;%\n  right_join(sales_report, by = \"Product\")\n\n\n\n\n4.2 sparklines in ggplot2\nThe code chunk used.\n\n\nShow the code\nggplot(sales_report, aes(x=Month, y=Sales)) + \n  facet_grid(Product ~ ., scales = \"free_y\") + \n  geom_ribbon(data = quarts, aes(ymin = quart1, max = quart2), \n              fill = 'grey90') +\n  geom_line(size=0.3) +\n  geom_point(data = mins, col = 'red') +\n  geom_point(data = maxs, col = 'blue') +\n  geom_text(data = mins, aes(label = Sales), vjust = -1) +\n  geom_text(data = maxs, aes(label = Sales), vjust = 2.5) +\n  geom_text(data = ends, aes(label = Sales), hjust = 0, nudge_x = 0.5) +\n  geom_text(data = ends, aes(label = Product), hjust = 0, nudge_x = 1.0) +\n  expand_limits(x = max(sales_report$Month) + \n                  (0.25 * (max(sales_report$Month) - min(sales_report$Month)))) +\n  scale_x_continuous(breaks = seq(1, 12, 1)) +\n  scale_y_continuous(expand = c(0.1, 0)) +\n  theme_tufte(base_size = 3, base_family = \"Helvetica\") +\n  theme(axis.title=element_blank(), axis.text.y = element_blank(), \n        axis.ticks = element_blank(), strip.text = element_blank())"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#static-information-dashboard-design-gt-and-gtextras-methods",
    "title": "Hands-on Exercise 10",
    "section": "5 Static Information Dashboard Design: gt and gtExtras methods",
    "text": "5 Static Information Dashboard Design: gt and gtExtras methods\nIn this section, you will learn how to create static information dashboard by using¬†gt¬†and¬†gtExtras¬†packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\n\n5.1 Plotting a simple bullet chart\nIn this section, you will learn how to prepare a bullet chart report by using functions of gt and gtExtras packages.\n\n\nShow the code\ninstall.packages(\"gtExtras\") \nlibrary(gtExtras) \nlibrary(dplyr)\nproduct %&gt;%\n  gt::gt() %&gt;%\n  gt_plt_bullet(column = current, \n              target = target, \n              width = 60,\n              palette = c(\"lightblue\", \n                          \"black\")) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\ncurrent\n\n\n\n\nAmaretto\n\n\n\n   \n\n\n\nCaffe Latte\n\n\n\n   \n\n\n\nCaffe Mocha\n\n\n\n   \n\n\n\nChamomile\n\n\n\n   \n\n\n\nColombian\n\n\n\n   \n\n\n\nDarjeeling\n\n\n\n   \n\n\n\nDecaf Espresso\n\n\n\n   \n\n\n\nDecaf Irish Cream\n\n\n\n   \n\n\n\nEarl Grey\n\n\n\n   \n\n\n\nGreen Tea\n\n\n\n   \n\n\n\nLemon\n\n\n\n   \n\n\n\nMint\n\n\n\n   \n\n\n\nRegular Espresso"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#sparklines-gtextras-method",
    "title": "Hands-on Exercise 10",
    "section": "6 sparklines: gtExtras method",
    "text": "6 sparklines: gtExtras method\nBefore we can prepare the sales report by product by using gtExtras functions, code chunk below will be used to prepare the data.\n\n\nShow the code\nlibrary(dplyr)\nlibrary(lubridate)\n\nreport &lt;- coffeechain %&gt;%\n  mutate(Year = year(Date)) %&gt;%\n  filter(Year == 2013) %&gt;%\n  mutate(Month = month(Date, label = TRUE, abbr = TRUE)) %&gt;%\n  group_by(Product, Month) %&gt;%\n  summarise(Sales = sum(Sales), .groups = \"drop\")\n\n\nIt is important to note that one of the requirement of gtExtras functions is that almost exclusively they require you to pass data.frame with list columns. In view of this, code chunk below will be used to convert the report data.frame into list columns.\n\n\nShow the code\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\n# A tibble: 13 √ó 2\n   Product           `Monthly Sales`\n   &lt;chr&gt;             &lt;list&gt;         \n 1 Amaretto          &lt;dbl [12]&gt;     \n 2 Caffe Latte       &lt;dbl [12]&gt;     \n 3 Caffe Mocha       &lt;dbl [12]&gt;     \n 4 Chamomile         &lt;dbl [12]&gt;     \n 5 Colombian         &lt;dbl [12]&gt;     \n 6 Darjeeling        &lt;dbl [12]&gt;     \n 7 Decaf Espresso    &lt;dbl [12]&gt;     \n 8 Decaf Irish Cream &lt;dbl [12]&gt;     \n 9 Earl Grey         &lt;dbl [12]&gt;     \n10 Green Tea         &lt;dbl [12]&gt;     \n11 Lemon             &lt;dbl [12]&gt;     \n12 Mint              &lt;dbl [12]&gt;     \n13 Regular Espresso  &lt;dbl [12]&gt;     \n\n\n\n6.1 Plotting Coffechain Sales report\n\n\nShow the code\nreport %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\") %&gt;%\n   gt() %&gt;%\n   gt_plt_sparkline('Monthly Sales',\n                    same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMonthly Sales\n\n\n\n\nAmaretto\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n\n\n\n   3.7K\n\n\n\nChamomile\n\n\n\n   3.3K\n\n\n\nColombian\n\n\n\n   5.5K\n\n\n\nDarjeeling\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n\n\n\n   2.7K\n\n\n\nEarl Grey\n\n\n\n   3.0K\n\n\n\nGreen Tea\n\n\n\n   1.5K\n\n\n\nLemon\n\n\n\n   4.4K\n\n\n\nMint\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n6.2 Adding statistics\nFirst, calculate summary statistics by using the code chunk below.\n\n\nShow the code\nreport %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            ) %&gt;%\n  gt() %&gt;%\n  fmt_number(columns = 4,\n    decimals = 2)\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\n\n\n\n\nAmaretto\n1016\n1210\n1,119.00\n\n\nCaffe Latte\n1398\n1653\n1,528.33\n\n\nCaffe Mocha\n3322\n3828\n3,613.92\n\n\nChamomile\n2967\n3395\n3,217.42\n\n\nColombian\n5132\n5961\n5,457.25\n\n\nDarjeeling\n2926\n3281\n3,112.67\n\n\nDecaf Espresso\n3181\n3493\n3,326.83\n\n\nDecaf Irish Cream\n2463\n2901\n2,648.25\n\n\nEarl Grey\n2730\n3005\n2,841.83\n\n\nGreen Tea\n1339\n1476\n1,398.75\n\n\nLemon\n3851\n4418\n4,080.83\n\n\nMint\n1388\n1669\n1,519.17\n\n\nRegular Espresso\n890\n1218\n1,023.42\n\n\n\n\n\n\n\n\n\n6.3 Combining the data.frame\nNext, use the code chunk below to add the statistics on the table.\n\n\nShow the code\nspark &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize('Monthly Sales' = list(Sales), \n            .groups = \"drop\")\n\n\n\n\nShow the code\nsales &lt;- report %&gt;% \n  group_by(Product) %&gt;% \n  summarise(\"Min\" = min(Sales, na.rm = T),\n            \"Max\" = max(Sales, na.rm = T),\n            \"Average\" = mean(Sales, na.rm = T)\n            )\n\n\n\n\nShow the code\nsales_data = left_join(sales, spark, by = \"Product\")\n\n\n\n\n6.4 Plotting the updated data.table\n\n\nShow the code\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales',\n                   same_limit = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K\n\n\n\n\n\n\n\n\n\n\n6.5 Combining bullet chart and sparklines\nSimilarly, we can combining the bullet chart and sparklines using the steps below.\n\n\nShow the code\nbullet &lt;- coffeechain %&gt;%\n  filter(Date &gt;= \"2013-01-01\") %&gt;%\n  group_by(`Product`) %&gt;%\n  summarise(`Target` = sum(`Budget Sales`),\n            `Actual` = sum(`Sales`)) %&gt;%\n  ungroup() \n\n\n\n\nShow the code\nsales_data = sales_data %&gt;%\n  left_join(bullet, by = \"Product\")\n\n\n\nnames(sales_data)\n\n[1] \"Product\"       \"Min\"           \"Max\"           \"Average\"      \n[5] \"Monthly Sales\" \"Target\"        \"Actual\"       \n\n\n\n\nShow the code\nlibrary(dplyr)\nlibrary(gt)\nlibrary(gtExtras)\n\nsales_data %&gt;%\n  gt() %&gt;%\n  gt_plt_sparkline('Monthly Sales') %&gt;%\n  gt_plt_bullet(\n    column = Actual,\n    target = Target,\n    width = 28,\n    palette = c(\"lightblue\", \"black\")\n  ) %&gt;%\n  gt_theme_538()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\nMin\nMax\nAverage\nMonthly Sales\nActual\n\n\n\n\nAmaretto\n1016\n1210\n1119.000\n\n\n\n   1.2K\n\n\n\n\n   \n\n\n\nCaffe Latte\n1398\n1653\n1528.333\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nCaffe Mocha\n3322\n3828\n3613.917\n\n\n\n   3.7K\n\n\n\n\n   \n\n\n\nChamomile\n2967\n3395\n3217.417\n\n\n\n   3.3K\n\n\n\n\n   \n\n\n\nColombian\n5132\n5961\n5457.250\n\n\n\n   5.5K\n\n\n\n\n   \n\n\n\nDarjeeling\n2926\n3281\n3112.667\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nDecaf Espresso\n3181\n3493\n3326.833\n\n\n\n   3.2K\n\n\n\n\n   \n\n\n\nDecaf Irish Cream\n2463\n2901\n2648.250\n\n\n\n   2.7K\n\n\n\n\n   \n\n\n\nEarl Grey\n2730\n3005\n2841.833\n\n\n\n   3.0K\n\n\n\n\n   \n\n\n\nGreen Tea\n1339\n1476\n1398.750\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nLemon\n3851\n4418\n4080.833\n\n\n\n   4.4K\n\n\n\n\n   \n\n\n\nMint\n1388\n1669\n1519.167\n\n\n\n   1.5K\n\n\n\n\n   \n\n\n\nRegular Espresso\n890\n1218\n1023.417\n\n\n\n   1.1K"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#interactive-information-dashboard-design-reactable-and-reactablefmtr-methods",
    "title": "Hands-on Exercise 10",
    "section": "7 Interactive Information Dashboard Design: reactable and reactablefmtr methods",
    "text": "7 Interactive Information Dashboard Design: reactable and reactablefmtr methods\nIn this section, you will learn how to create interactive information dashboard by using reactable and reactablefmtr packages. Before getting started, it is highly recommended for you to visit the webpage of these two packages and review all the materials provided on the webpages at least once. You done not have to understand and remember everything provided but at least have an overview of the purposes and functions provided by them.\nIn order to build an interactive sparklines, we need to install dataui R package by using the code chunk below.\n\n\nShow the code\nremotes::install_github(\"timelyportfolio/dataui\")\n\n\nNext, you all need to load the package onto R environment by using the code chunk below.\n\n\nShow the code\nlibrary(dataui)\n\n\n\n7.1 Plotting interactive sparklines\nSimilar to gtExtras, to plot an interactive sparklines by using reactablefmtr package we need to prepare the list field by using the code chunk below.\n\n\nShow the code\nreport &lt;- report %&gt;%\n  group_by(Product) %&gt;%\n  summarize(`Monthly Sales` = list(Sales))\n\n\nNext,¬†react_sparkline¬†will be to plot the sparklines as shown below.\n\n\nShow the code\nreactable(\n  report,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\n7.2 Changing the pagesize\nBy default the pagesize is 10. In the code chunk below, arguments defaultPageSize is used to change the default setting.\n\n\nShow the code\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(report)\n    )\n  )\n)\n\n\n\n\n\n\n\n\n7.3 Adding points and labels\nIn the code chunk below¬†highlight_points¬†argument is used to show the minimum and maximum values points and¬†label¬†argument is used to label first and last values.\n\n\nShow the code\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        labels = c(\"first\", \"last\")\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\n7.4 Adding reference line\nIn the code chunk below¬†statline¬†argument is used to show the mean line.\n\n\nShow the code\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        statline = \"mean\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\n7.5 Adding bandline\nInstead adding reference line, bandline can be added by using the¬†bandline¬†argument.\n\n\nShow the code\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkline(\n        report,\n        highlight_points = highlight_points(\n          min = \"red\", max = \"blue\"),\n        line_width = 1,\n        bandline = \"innerquartiles\",\n        bandline_color = \"green\"\n        )\n    )\n  )\n)\n\n\n\n\n\n\n\n\n7.6 Changing from sparkline to sparkbar\nInstead of displaying the values as sparklines, we can display them as sparkbars as shiwn below.\n\n\nShow the code\nreactable(\n  report,\n  defaultPageSize = 13,\n  columns = list(\n    Product = colDef(maxWidth = 200),\n    `Monthly Sales` = colDef(\n      cell = react_sparkbar(\n        report,\n        highlight_bars = highlight_bars(\n          min = \"red\", max = \"blue\"),\n        bandline = \"innerquartiles\",\n        statline = \"mean\")\n    )\n  )\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#superstore-sales-vs-profit-interactive-plot",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#superstore-sales-vs-profit-interactive-plot",
    "title": "In-class Exercise 3",
    "section": "2 Superstore Sales vs Profit Interactive Plot",
    "text": "2 Superstore Sales vs Profit Interactive Plot\nHere is the sales vs profit interactive plot visualized using Tableau:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore is a highly urbanized and densely populated nation, where population distribution varies significantly across regions and demographic groups. Gaining insights into these spatial and age-related patterns is critical for informed urban planning, resource allocation, and policy formulation.\n\n\n\nThis take-home exercise aims to uncover key demographic insights from Singapore‚Äôs 2024 resident population dataset. Specifically, it seeks to:\n\nAnalyze the age structure across planning areas\nExplore gender ratios across different regions\nIdentify regions with higher concentrations of children or elderly residents"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore is a highly urbanized and densely populated nation, where population distribution varies significantly across regions and demographic groups. Gaining insights into these spatial and age-related patterns is critical for informed urban planning, resource allocation, and policy formulation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "This take-home exercise aims to uncover key demographic insights from Singapore‚Äôs 2024 resident population dataset. Specifically, it seeks to:\n\nAnalyze the age structure across planning areas\nExplore gender ratios across different regions\nIdentify regions with higher concentrations of children or elderly residents"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#tools-used",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#tools-used",
    "title": "Take-home Exercise 1",
    "section": "2.1 Tools Used",
    "text": "2.1 Tools Used\nThe following R packages were utilized for data pre-processing and visualization:\n\npacman::p_load(plotly, tidyverse, DT, ggiraph, patchwork, ggstatsplot, GGally, corrplot)\n\n\ntidyverse: Provides a collection of packages (including dplyr, ggplot2, readr) for data manipulation, transformation, and visualization. It forms the core of data wrangling and plotting throughout this analysis.\nggiraph: Enables interactive versions of ggplot2 graphics, allowing for tooltips and hover interactions in visualizations such as the population pyramid and bar charts.\nplotly: Used to render interactive ggplot outputs in cases like ggplotly() if included (though in your shared code, the output rendering is primarily done via girafe() from ggiraph).\nDT: Provides a wrapper for the JavaScript DataTables library. It is used to display interactive, searchable, and scrollable HTML tables, useful for previewing datasets after each cleaning step.\npatchwork: A layout manager for combining multiple ggplot2 plots into a cohesive visual grid using a simple and expressive syntax like plot1 + plot2. It helps in creating dashboards or side-by-side comparisons.\nggstatsplot: Simplifies statistical visualization by integrating results such as p-values, effect sizes, and confidence intervals directly into ggplot2 charts. Useful for comparing group differences and testing statistical significance visually.\nGGally: Extends ggplot2 by adding functions like ggpairs() for plotting pairwise relationships between variables. It is particularly useful in exploratory data analysis to visualize correlations and distributions across multiple dimensions.\ncorrplot: Specializes in visualizing correlation matrices through heatmaps, circle plots, and color gradients. Helps in identifying variable relationships and multicollinearity in datasets."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-source",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-source",
    "title": "Take-home Exercise 1",
    "section": "2.2 Data Source",
    "text": "2.2 Data Source\nThe dataset originates from Singapore‚Äôs Department of Statistics (DOS) and contains:\n\nPA: Planning Area\nSZ: Subzone\nAge: Age (ranging from 0 to 100+)\nSex: Gender (Males / Females)\nPop: Number of residents\nTime: Year of observation (2024)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data",
    "title": "Take-home Exercise 1",
    "section": "3.1 Import Data",
    "text": "3.1 Import Data\n\nrespop &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-cleaning",
    "title": "Take-home Exercise 1",
    "section": "3.2 Data Cleaning",
    "text": "3.2 Data Cleaning\nTo ensure the dataset is clean and ready for analysis, the following steps were performed:\n\n3.2.1 Step 1: Remove Duplicates\nRemove any duplicated rows to avoid double-counting:\n\nThe Code ChunkData Table\n\n\n\nrespop &lt;- distinct(respop)\nDT::datatable(head(respop), options = list(scrollX = TRUE), caption = \"After Removing Duplicates\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Step 2: Handle Missing Values\nEnsure there are no missing or malformed entries in critical columns:\n\nThe Code ChunkData Table\n\n\n\nrespop &lt;- drop_na(respop)\nDT::datatable(head(respop), options = list(scrollX = TRUE), caption = \"After Dropping Missing Values\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Step 3: Standardize Age Format\nThe Age column includes a non-numeric category \"90_and_Over\" which cannot be coerced into an integer. We convert this category into a numeric age of 90, representing a minimum estimate for analysis:\n\nThe Code ChunkData Table\n\n\n\nrespop &lt;- respop %&gt;%\n  mutate(Age = ifelse(Age == \"90_and_Over\", \"90\", Age),\n         Age = as.integer(Age))\nDT::datatable(head(respop), options = list(scrollX = TRUE), caption = \"After Converting Age Format\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis allows us to include elderly population data in age-based analyses such as population pyramids and dependency ratios.\n\n\n\n\n3.2.4 Step 4: Convert Column Types\nEnsure categorical and numeric columns are properly formatted:\n\nThe Code ChunkData Table\n\n\n\nrespop &lt;- respop %&gt;%\n  mutate(\n    Sex = as.factor(Sex),\n    PA = as.factor(PA),\n    SZ = as.factor(SZ)\n  )\nDT::datatable(head(respop), options = list(scrollX = TRUE), caption = \"After Converting Column Types\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#population-pyramid-of-singapore-by-age-group",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#population-pyramid-of-singapore-by-age-group",
    "title": "Take-home Exercise 1",
    "section": "4.1 Population Pyramid of Singapore by Age Group",
    "text": "4.1 Population Pyramid of Singapore by Age Group\nThis section creates an interactive population pyramid for the entire Singapore resident population in 2024. It groups ages into 5-year intervals and displays male and female populations using diverging bars. Tooltips appear when hovering over each bar.\n\n4.1.1 Step 1: Load Libraries\nWe use tidyverse for data manipulation and ggiraph for interactive plotting.\n\nlibrary(tidyverse)\nlibrary(ggiraph)\n\n\n\n4.1.2 Step 2: Prepare Population Pyramid Data with Age Groups and Tooltips\n\nConvert age to numeric;\nBin ages into groups like \"0‚Äì4\", \"5‚Äì9\", ‚Ä¶;\nSummarize population by Sex and AgeGrp;\nMake male population negative to mirror the pyramid;\nAdd a tooltip_text column for interactive tooltips.\n\n\npyramid_sg &lt;- respop %&gt;%\n  mutate(\n    Age = as.numeric(Age),\n    AgeGrp = cut(\n      Age,\n      breaks = c(0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49,\n                 54, 59, 64, 69, 74, 79, 84, 89, 94, 99, Inf),\n      labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                 \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                 \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                 \"75-79\", \"80-84\", \"85-89\", \"90-94\", \"95-99\", \"100+\"),\n      right = FALSE\n    )\n  ) %&gt;%\n  group_by(Sex, AgeGrp) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\") %&gt;%\n  mutate(\n    Pop_signed = ifelse(Sex == \"Males\", -Pop, Pop),\n    Label = paste0(round(Pop / 1000), \"k\"),\n    tooltip_text = paste0(\"Age Group: \", AgeGrp,\n                          \"&lt;br&gt;Sex: \", Sex,\n                          \"&lt;br&gt;Population: \", format(Pop, big.mark = \",\"))\n  )\n\n\n\n4.1.3 Step 3: Build Interactive ggplot Object\nWe use geom_bar_interactive() from ggiraph to: Create diverging bars (left = males, right = females), Attach the tooltip text, Color-code by gender.\n\nmax_val &lt;- max(pyramid_sg$Pop)\n\npyramid_male &lt;- pyramid_sg %&gt;% filter(Sex == \"Males\")\npyramid_female &lt;- pyramid_sg %&gt;% filter(Sex == \"Females\")\n\ngg &lt;- ggplot(pyramid_sg, aes(x = AgeGrp, y = Pop_signed, fill = Sex,\n                             tooltip = tooltip_text, data_id = AgeGrp)) +\n  geom_bar_interactive(stat = \"identity\", width = 0.8) +\n  geom_text(data = pyramid_male,\n            aes(label = Label),\n            hjust = 1.1, size = 3, color = \"black\") +\n  geom_text(data = pyramid_female,\n            aes(label = Label),\n            hjust = -0.1, size = 3, color = \"black\") +\n  coord_flip() +\n  scale_y_continuous(limits = c(-1.1 * max_val, 1.1 * max_val),\n                     labels = ~ paste0(abs(.x / 1000), \"k\")) +\n  scale_fill_manual(values = c(\"Males\" = \"#1f77b4\", \"Females\" = \"#ff7f0e\")) +\n  theme_minimal() +\n  labs(title = \"Interactive Population Pyramid of Singapore (2024)\",\n       x = \"Age Group\", y = \"Population\", fill = \"Sex\")\n\n\n\n4.1.4 Step 4: Render as Interactive Widget\nWe finally call girafe() to render the interactive graphic. We also customize the tooltip style using CSS.\n\ngirafe(ggobj = gg,\n       width_svg = 8, height_svg = 6,\n       options = list(\n         opts_tooltip(css = \"background-color:white; color:black; border:1px solid gray; padding:5px;\"),\n         opts_hover(css = \"fill-opacity:0.8;cursor:pointer;\")\n       ))\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe population pyramid clearly visualizes demographic trends such as a strong middle-aged working population and a gradually tapering older population, indicative of an aging society with slowing birth rates."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-ratio-by-planning-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#gender-ratio-by-planning-area",
    "title": "Take-home Exercise 1",
    "section": "4.2 Gender Ratio by Planning Area",
    "text": "4.2 Gender Ratio by Planning Area\nThis section displays the male-to-female population ratio for each Singapore planning area. It uses color to indicate whether an area has more males, more females, or is balanced, and includes interactive tooltips for details.\n\n4.2.1 Step 1: Load Required Libraries\nWe use tidyverse for data wrangling and ggiraph for creating interactive graphics.\n\nlibrary(tidyverse)\nlibrary(ggiraph)\n\n\n\n4.2.2 Step 2: Calculate Gender Ratio and Prepare Tooltip\n\nGroup data by PA and Sex;\nSummarize total male and female population;\nCalculate the gender ratio (Males / Females);\nClassify each area into \"More Males\", \"More Females\", or \"Balanced\";\nFilter out areas with very small populations (Total_Pop &lt;= 100);\nAdd a Tooltip column to be displayed when hovering.\n\n\ngender_ratio &lt;- respop %&gt;%\n  group_by(PA, Sex) %&gt;%\n  summarise(Total = sum(Pop), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = Sex, values_from = Total) %&gt;%\n  mutate(Total_Pop = Males + Females) %&gt;%\n  filter(Total_Pop &gt; 100) %&gt;% \n  mutate(\n    Ratio = round(Males / Females, 2),\n    Status = case_when(\n      Ratio &gt; 1.05 ~ \"More Males\",\n      Ratio &lt; 0.95 ~ \"More Females\",\n      TRUE ~ \"Balanced\"\n    ),\n    Tooltip = paste0(\"Planning Area: \", PA,\n                     \"\\nMales: \", format(Males, big.mark = \",\"),\n                     \"\\nFemales: \", format(Females, big.mark = \",\"),\n                     \"\\nRatio (M/F): \", Ratio),\n    Label = as.character(Ratio)\n  )\n\n\n\n4.2.3 Step 3: Create the ggplot Object with Interactive Bars\nWe create a horizontal bar chart with:\n\nColor-coded bars based on Status;\nTooltip on hover (using geom_col_interactive);\nLabels showing exact ratio values;\nSmaller y-axis text for better readability.\n\n\ngg &lt;- ggplot(gender_ratio,\n             aes(x = reorder(PA, Ratio), y = Ratio,\n                 fill = Status,\n                 tooltip = Tooltip, data_id = PA)) +\n  geom_col_interactive(width = 0.7) +\n  geom_text(aes(label = Label),\n            hjust = -0.1, color = \"black\", size = 3) + \n  scale_fill_manual(values = c(\"More Males\" = \"#1f77b4\",\n                               \"More Females\" = \"#ff7f0e\",\n                               \"Balanced\" = \"#66c2a5\")) +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 7),\n    plot.margin = margin(r = 20) \n  ) +\n  labs(title = \"Interactive Gender Ratio by Planning Area (M/F)\",\n       x = \"Planning Area\", y = \"Male-to-Female Ratio\")\n\n\n\n4.2.4 Step 4: Render Interactive Widget\nWe use girafe() to display the chart with hover tooltips and styling.\n\ngirafe(ggobj = gg,\n       width_svg = 8, height_svg = 6,\n       options = list(\n         opts_tooltip(css = \"background-color:white;color:black;border:1px solid gray;padding:5px;\"),\n         opts_hover(css = \"fill-opacity:0.8;cursor:pointer;\")\n       ))\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nMost areas show balanced gender distributions, though some regions‚Äîsuch as Sungei Kadut and Changi‚Äîexhibit significant gender disparities, which may be related to industrial land use or specific housing demographics."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#total-population-by-planning-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#total-population-by-planning-area",
    "title": "Take-home Exercise 1",
    "section": "4.3 Total Population by Planning Area",
    "text": "4.3 Total Population by Planning Area\nThis section presents the total 2024 population for each planning area in Singapore using an interactive bar chart. Tooltips reveal the exact population figures on hover, and low-population areas are excluded to improve readability.\n\n4.3.1 Step 1: Load Required Libraries\nWe load tidyverse for data manipulation and ggiraph for interactive plotting.\n\nlibrary(tidyverse)\nlibrary(ggiraph)\n\n\n\n4.3.2 Step 2: Aggregate and Filter Population Data\n\nGroup the dataset by PA (planning area);\nSummarize total population (Total_Pop);\nFilter out areas with negligible population (e.g., below 100);\nAdd a Tooltip column with formatted text for display.\n\n\ntotal_pop &lt;- respop %&gt;%\n  group_by(PA) %&gt;%\n  summarise(Total_Pop = sum(Pop), .groups = \"drop\") %&gt;%\n  filter(Total_Pop &gt; 100) %&gt;%\n  mutate(\n    Tooltip = paste0(\"Planning Area: \", PA,\n                     \"\\nPopulation: \", format(Total_Pop, big.mark = \",\")),\n    Label = paste0(round(Total_Pop / 1000), \"k\")\n  )\n\n\n\n4.3.3 Step 3: Build Interactive ggplot Object\n\nReorder planning areas by total population;\nAdd tooltips via geom_col_interactive();\nFlip coordinates for clearer labels;\nSet minimalist theme and small font for y-axis.\n\n\nmax_val &lt;- max(total_pop$Total_Pop)\n\ngg &lt;- ggplot(total_pop, aes(x = reorder(PA, Total_Pop), y = Total_Pop,\n                            tooltip = Tooltip, data_id = PA)) +\n  geom_col_interactive(fill = \"#2ca02c\", width = 0.7) +\n  geom_text(aes(label = Label),\n            hjust = -0.1, color = \"black\", size = 3) + \n  coord_flip() +\n  scale_y_continuous(\n    labels = ~ paste0(.x / 1000, \"k\"),\n    limits = c(0, max_val * 1.1) \n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 7),\n        plot.margin = margin(r = 30)) +  \n  labs(title = \"Interactive Total Population by Planning Area (2024)\",\n       x = \"Planning Area\", y = \"Total Population\")\n\n\n\n4.3.4 Step 4: Render Interactive Widget\nWe render the final output using girafe(), and customize the tooltip style with CSS.\n\ngirafe(ggobj = gg,\n       width_svg = 8, height_svg = 6,\n       options = list(\n         opts_tooltip(css = \"background-color:white;color:black;border:1px solid gray;padding:5px;\"),\n         opts_hover(css = \"fill-opacity:0.8;cursor:pointer;\")\n       ))\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nHighly populated areas such as Tampines, Bedok, and Sengkang stand out, reinforcing their role as major residential zones requiring more public services, infrastructure, and transport support."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion-1",
    "title": "Take-home Exercise 1",
    "section": "6.1 Conclusion",
    "text": "6.1 Conclusion\nThis take-home exercise demonstrates how demographic data‚Äîwhen effectively cleaned, grouped, and visualized‚Äîcan provide valuable insights for government and planners. Visualizing age structures, gender distribution, and population concentrations can guide more equitable and efficient decisions in housing, transportation, healthcare, and education."
  }
]